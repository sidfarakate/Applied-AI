{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kK3alCdFflQX"
   },
   "source": [
    "### CNN on CIFR Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHCYMwwXflQd"
   },
   "source": [
    "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
    "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
    "3.  You cannot use DropOut layers.\n",
    "4.  You MUST use Image Augmentation Techniques.\n",
    "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
    "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
    "7.  You cannot use test images for training the model.\n",
    "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
    "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
    "10. You cannot have more than 1 Million parameters in total\n",
    "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
    "12. You can use any optimization algorithm you need. \n",
    "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:31.359796Z",
     "iopub.status.busy": "2022-12-08T09:25:31.358678Z",
     "iopub.status.idle": "2022-12-08T09:25:33.329840Z",
     "shell.execute_reply": "2022-12-08T09:25:33.328752Z",
     "shell.execute_reply.started": "2022-12-08T09:25:31.359707Z"
    },
    "id": "TLVcyNYKflQi"
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.datasets import cifar10\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "# from keras.layers import Concatenate\n",
    "# from keras.optimizers import Adam\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:33.339278Z",
     "iopub.status.busy": "2022-12-08T09:25:33.338826Z",
     "iopub.status.idle": "2022-12-08T09:25:33.344524Z",
     "shell.execute_reply": "2022-12-08T09:25:33.343131Z",
     "shell.execute_reply.started": "2022-12-08T09:25:33.339233Z"
    }
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:33.346977Z",
     "iopub.status.busy": "2022-12-08T09:25:33.346242Z",
     "iopub.status.idle": "2022-12-08T09:25:34.679423Z",
     "shell.execute_reply": "2022-12-08T09:25:34.678357Z",
     "shell.execute_reply.started": "2022-12-08T09:25:33.346927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# Pre-processing\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:34.683423Z",
     "iopub.status.busy": "2022-12-08T09:25:34.683087Z",
     "iopub.status.idle": "2022-12-08T09:25:34.691298Z",
     "shell.execute_reply": "2022-12-08T09:25:34.690127Z",
     "shell.execute_reply.started": "2022-12-08T09:25:34.683392Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:34.693820Z",
     "iopub.status.busy": "2022-12-08T09:25:34.692655Z",
     "iopub.status.idle": "2022-12-08T09:25:34.714057Z",
     "shell.execute_reply": "2022-12-08T09:25:34.712842Z",
     "shell.execute_reply.started": "2022-12-08T09:25:34.693780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 32):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        \n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "# transition Block\n",
    "def transition(input, num_filter = 32):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    \n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:34.716362Z",
     "iopub.status.busy": "2022-12-08T09:25:34.715949Z",
     "iopub.status.idle": "2022-12-08T09:25:34.728718Z",
     "shell.execute_reply": "2022-12-08T09:25:34.727876Z",
     "shell.execute_reply.started": "2022-12-08T09:25:34.716304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "l = 5\n",
    "num_filter = 45\n",
    "compression = 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:34.730310Z",
     "iopub.status.busy": "2022-12-08T09:25:34.730013Z",
     "iopub.status.idle": "2022-12-08T09:25:37.411543Z",
     "shell.execute_reply": "2022-12-08T09:25:37.410484Z",
     "shell.execute_reply.started": "2022-12-08T09:25:34.730283Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 09:25:34.845625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:34.846464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:34.856829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:34.857643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:34.858385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:34.859112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:34.860173: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-08 09:25:35.097101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:35.098058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:35.098897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:35.099728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:35.100505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:35.101244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:36.403563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:36.404545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:36.405407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:36.406242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:36.407019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:36.407783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-12-08 09:25:36.408240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-08 09:25:36.409010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter)\n",
    "First_Transition = transition(First_Block, num_filter)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter)\n",
    "Second_Transition = transition(Second_Block, num_filter)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter)\n",
    "Third_Transition = transition(Third_Block, num_filter)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:37.413435Z",
     "iopub.status.busy": "2022-12-08T09:25:37.413021Z",
     "iopub.status.idle": "2022-12-08T09:25:37.456823Z",
     "shell.execute_reply": "2022-12-08T09:25:37.455736Z",
     "shell.execute_reply.started": "2022-12-08T09:25:37.413387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 45)   1215        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 45)   180         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 45)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 41)   16605       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 86)   0           conv2d[0][0]                     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 86)   344         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 86)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 41)   31734       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 127)  0           concatenate[0][0]                \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 127)  508         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 127)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 41)   46863       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 168)  0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 168)  672         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 168)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 41)   61992       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 209)  0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 209)  836         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 209)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 41)   77121       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 250)  0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 250)  1000        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 250)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 41)   10250       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 41)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 41)   164         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 41)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 41)   15129       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 82)   0           average_pooling2d[0][0]          \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 82)   328         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 82)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 41)   30258       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 123)  0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 123)  492         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 123)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 41)   45387       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 164)  0           concatenate_6[0][0]              \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 164)  656         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 164)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 41)   60516       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 205)  0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 205)  820         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 205)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 41)   75645       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 246)  0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 246)  984         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 246)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 41)   10086       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 41)     0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 41)     164         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 41)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 41)     15129       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 82)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 82)     328         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 82)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 41)     30258       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 8, 8, 123)    0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 123)    492         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 123)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 41)     45387       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 8, 8, 164)    0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 164)    656         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 164)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 41)     60516       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 8, 8, 205)    0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 205)    820         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 205)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 41)     75645       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 8, 8, 246)    0           concatenate_13[0][0]             \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 246)    984         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 246)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 41)     10086       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 41)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 41)     164         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 41)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 41)     15129       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 4, 4, 82)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 82)     328         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 82)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 41)     30258       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 4, 4, 123)    0           concatenate_15[0][0]             \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 123)    492         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 123)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 4, 41)     45387       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 4, 4, 164)    0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 164)    656         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 164)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 4, 41)     60516       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 4, 4, 205)    0           concatenate_17[0][0]             \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 205)    820         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 205)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 41)     75645       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 4, 4, 246)    0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 4, 246)    984         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 246)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 246)    0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 984)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           9850        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 970,479\n",
      "Trainable params: 963,543\n",
      "Non-trainable params: 6,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:37.460728Z",
     "iopub.status.busy": "2022-12-08T09:25:37.459270Z",
     "iopub.status.idle": "2022-12-08T09:25:37.467525Z",
     "shell.execute_reply": "2022-12-08T09:25:37.466341Z",
     "shell.execute_reply.started": "2022-12-08T09:25:37.460683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:37.469569Z",
     "iopub.status.busy": "2022-12-08T09:25:37.469022Z",
     "iopub.status.idle": "2022-12-08T09:25:37.489027Z",
     "shell.execute_reply": "2022-12-08T09:25:37.487818Z",
     "shell.execute_reply.started": "2022-12-08T09:25:37.469527Z"
    }
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:37.491434Z",
     "iopub.status.busy": "2022-12-08T09:25:37.490812Z",
     "iopub.status.idle": "2022-12-08T09:25:37.498688Z",
     "shell.execute_reply": "2022-12-08T09:25:37.497412Z",
     "shell.execute_reply.started": "2022-12-08T09:25:37.491393Z"
    }
   },
   "outputs": [],
   "source": [
    "# ref: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            rotation_range=25,  \n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.15,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T09:25:37.501232Z",
     "iopub.status.busy": "2022-12-08T09:25:37.500539Z",
     "iopub.status.idle": "2022-12-08T12:59:24.529925Z",
     "shell.execute_reply": "2022-12-08T12:59:24.528896Z",
     "shell.execute_reply.started": "2022-12-08T09:25:37.501192Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 09:25:37.849928: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 09:25:41.017274: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 71s 162ms/step - loss: 1.5476 - accuracy: 0.4352 - val_loss: 2.2533 - val_accuracy: 0.2697\n",
      "Epoch 2/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 1.1662 - accuracy: 0.5813 - val_loss: 1.5167 - val_accuracy: 0.5070\n",
      "Epoch 3/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.9629 - accuracy: 0.6590 - val_loss: 1.2649 - val_accuracy: 0.5681\n",
      "Epoch 4/215\n",
      "390/390 [==============================] - 63s 161ms/step - loss: 0.8474 - accuracy: 0.7040 - val_loss: 1.1419 - val_accuracy: 0.6277\n",
      "Epoch 5/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.7653 - accuracy: 0.7330 - val_loss: 1.0793 - val_accuracy: 0.6335\n",
      "Epoch 6/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.7027 - accuracy: 0.7544 - val_loss: 1.0204 - val_accuracy: 0.6462\n",
      "Epoch 7/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.6566 - accuracy: 0.7705 - val_loss: 1.0136 - val_accuracy: 0.6681\n",
      "Epoch 8/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.6120 - accuracy: 0.7867 - val_loss: 0.7307 - val_accuracy: 0.7462\n",
      "Epoch 9/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.5810 - accuracy: 0.7976 - val_loss: 1.4133 - val_accuracy: 0.6026\n",
      "Epoch 10/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.5500 - accuracy: 0.8099 - val_loss: 0.8448 - val_accuracy: 0.7219\n",
      "Epoch 11/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.5300 - accuracy: 0.8157 - val_loss: 0.7319 - val_accuracy: 0.7528\n",
      "Epoch 12/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.5068 - accuracy: 0.8261 - val_loss: 0.6949 - val_accuracy: 0.7673\n",
      "Epoch 13/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.4823 - accuracy: 0.8320 - val_loss: 0.7076 - val_accuracy: 0.7555\n",
      "Epoch 14/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.4721 - accuracy: 0.8353 - val_loss: 0.6731 - val_accuracy: 0.7713\n",
      "Epoch 15/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.4483 - accuracy: 0.8426 - val_loss: 0.7423 - val_accuracy: 0.7529\n",
      "Epoch 16/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.4388 - accuracy: 0.8478 - val_loss: 0.6782 - val_accuracy: 0.7739\n",
      "Epoch 17/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.4264 - accuracy: 0.8531 - val_loss: 0.5586 - val_accuracy: 0.8136\n",
      "Epoch 18/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.4110 - accuracy: 0.8561 - val_loss: 0.5932 - val_accuracy: 0.8000\n",
      "Epoch 19/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3975 - accuracy: 0.8605 - val_loss: 0.6145 - val_accuracy: 0.7953\n",
      "Epoch 20/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3846 - accuracy: 0.8658 - val_loss: 0.6309 - val_accuracy: 0.7888\n",
      "Epoch 21/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.3763 - accuracy: 0.8695 - val_loss: 0.6620 - val_accuracy: 0.7879\n",
      "Epoch 22/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3691 - accuracy: 0.8727 - val_loss: 0.6542 - val_accuracy: 0.7856\n",
      "Epoch 23/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.3579 - accuracy: 0.8734 - val_loss: 0.6930 - val_accuracy: 0.7764\n",
      "Epoch 24/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3530 - accuracy: 0.8765 - val_loss: 0.5250 - val_accuracy: 0.8237\n",
      "Epoch 25/215\n",
      "390/390 [==============================] - 63s 161ms/step - loss: 0.3381 - accuracy: 0.8822 - val_loss: 0.5664 - val_accuracy: 0.8135\n",
      "Epoch 26/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3349 - accuracy: 0.8833 - val_loss: 0.4782 - val_accuracy: 0.8437\n",
      "Epoch 27/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.3263 - accuracy: 0.8865 - val_loss: 0.5455 - val_accuracy: 0.8166\n",
      "Epoch 28/215\n",
      "390/390 [==============================] - 63s 160ms/step - loss: 0.3191 - accuracy: 0.8892 - val_loss: 0.4828 - val_accuracy: 0.8341\n",
      "Epoch 29/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.3083 - accuracy: 0.8933 - val_loss: 0.5578 - val_accuracy: 0.8113\n",
      "Epoch 30/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.3068 - accuracy: 0.8919 - val_loss: 0.5298 - val_accuracy: 0.8265\n",
      "Epoch 31/215\n",
      "390/390 [==============================] - 59s 150ms/step - loss: 0.3023 - accuracy: 0.8929 - val_loss: 0.4855 - val_accuracy: 0.8401\n",
      "Epoch 32/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2951 - accuracy: 0.8958 - val_loss: 0.6361 - val_accuracy: 0.8018\n",
      "Epoch 33/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.2851 - accuracy: 0.9005 - val_loss: 0.5441 - val_accuracy: 0.8292\n",
      "Epoch 34/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2845 - accuracy: 0.9011 - val_loss: 0.4862 - val_accuracy: 0.8431\n",
      "Epoch 35/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2746 - accuracy: 0.9038 - val_loss: 0.4000 - val_accuracy: 0.8615\n",
      "Epoch 36/215\n",
      "390/390 [==============================] - 63s 160ms/step - loss: 0.2744 - accuracy: 0.9037 - val_loss: 0.5728 - val_accuracy: 0.8059\n",
      "Epoch 37/215\n",
      "390/390 [==============================] - 59s 151ms/step - loss: 0.2659 - accuracy: 0.9066 - val_loss: 0.6696 - val_accuracy: 0.7939\n",
      "Epoch 38/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2615 - accuracy: 0.9085 - val_loss: 0.4566 - val_accuracy: 0.8527\n",
      "Epoch 39/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2595 - accuracy: 0.9094 - val_loss: 0.4893 - val_accuracy: 0.8436\n",
      "Epoch 40/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.2566 - accuracy: 0.9093 - val_loss: 0.5679 - val_accuracy: 0.8226\n",
      "Epoch 41/215\n",
      "390/390 [==============================] - 63s 161ms/step - loss: 0.2462 - accuracy: 0.9137 - val_loss: 0.4084 - val_accuracy: 0.8687\n",
      "Epoch 42/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.2451 - accuracy: 0.9142 - val_loss: 0.5579 - val_accuracy: 0.8205\n",
      "Epoch 43/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2423 - accuracy: 0.9161 - val_loss: 0.5519 - val_accuracy: 0.8220\n",
      "Epoch 44/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.2382 - accuracy: 0.9160 - val_loss: 0.5281 - val_accuracy: 0.8306\n",
      "Epoch 45/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.2343 - accuracy: 0.9178 - val_loss: 0.4392 - val_accuracy: 0.8521\n",
      "Epoch 46/215\n",
      "390/390 [==============================] - 59s 151ms/step - loss: 0.2276 - accuracy: 0.9214 - val_loss: 0.4139 - val_accuracy: 0.8629\n",
      "Epoch 47/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2239 - accuracy: 0.9208 - val_loss: 0.4698 - val_accuracy: 0.8455\n",
      "Epoch 48/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.2236 - accuracy: 0.9229 - val_loss: 0.3982 - val_accuracy: 0.8698\n",
      "Epoch 49/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.2231 - accuracy: 0.9212 - val_loss: 0.4152 - val_accuracy: 0.8651\n",
      "Epoch 50/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2142 - accuracy: 0.9247 - val_loss: 0.4429 - val_accuracy: 0.8598\n",
      "Epoch 51/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.2081 - accuracy: 0.9268 - val_loss: 0.4847 - val_accuracy: 0.8447\n",
      "Epoch 52/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.2071 - accuracy: 0.9264 - val_loss: 0.4109 - val_accuracy: 0.8667\n",
      "Epoch 53/215\n",
      "390/390 [==============================] - 59s 151ms/step - loss: 0.2058 - accuracy: 0.9272 - val_loss: 0.4726 - val_accuracy: 0.8511\n",
      "Epoch 54/215\n",
      "390/390 [==============================] - 63s 161ms/step - loss: 0.2025 - accuracy: 0.9287 - val_loss: 0.4374 - val_accuracy: 0.8550\n",
      "Epoch 55/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.2023 - accuracy: 0.9280 - val_loss: 0.4047 - val_accuracy: 0.8695\n",
      "Epoch 56/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.2007 - accuracy: 0.9301 - val_loss: 0.3930 - val_accuracy: 0.8740\n",
      "Epoch 57/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1930 - accuracy: 0.9317 - val_loss: 0.4256 - val_accuracy: 0.8641\n",
      "Epoch 58/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.1937 - accuracy: 0.9307 - val_loss: 0.4687 - val_accuracy: 0.8547\n",
      "Epoch 59/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1907 - accuracy: 0.9324 - val_loss: 0.4487 - val_accuracy: 0.8551\n",
      "Epoch 60/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.1886 - accuracy: 0.9336 - val_loss: 0.4221 - val_accuracy: 0.8708\n",
      "Epoch 61/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1864 - accuracy: 0.9348 - val_loss: 0.4623 - val_accuracy: 0.8552\n",
      "Epoch 62/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1821 - accuracy: 0.9364 - val_loss: 0.4398 - val_accuracy: 0.8636\n",
      "Epoch 63/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.1783 - accuracy: 0.9374 - val_loss: 0.5091 - val_accuracy: 0.8408\n",
      "Epoch 64/215\n",
      "390/390 [==============================] - 62s 159ms/step - loss: 0.1798 - accuracy: 0.9376 - val_loss: 0.4798 - val_accuracy: 0.8500\n",
      "Epoch 65/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1780 - accuracy: 0.9372 - val_loss: 0.3564 - val_accuracy: 0.8860\n",
      "Epoch 66/215\n",
      "390/390 [==============================] - 59s 151ms/step - loss: 0.1770 - accuracy: 0.9369 - val_loss: 0.4190 - val_accuracy: 0.8704\n",
      "Epoch 67/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1752 - accuracy: 0.9382 - val_loss: 0.4187 - val_accuracy: 0.8680\n",
      "Epoch 68/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1717 - accuracy: 0.9394 - val_loss: 0.3892 - val_accuracy: 0.8811\n",
      "Epoch 69/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1665 - accuracy: 0.9412 - val_loss: 0.4080 - val_accuracy: 0.8684\n",
      "Epoch 70/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1635 - accuracy: 0.9408 - val_loss: 0.4100 - val_accuracy: 0.8704\n",
      "Epoch 71/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1636 - accuracy: 0.9413 - val_loss: 0.4573 - val_accuracy: 0.8606\n",
      "Epoch 72/215\n",
      "390/390 [==============================] - 63s 160ms/step - loss: 0.1610 - accuracy: 0.9439 - val_loss: 0.4243 - val_accuracy: 0.8738\n",
      "Epoch 73/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.1596 - accuracy: 0.9437 - val_loss: 0.3873 - val_accuracy: 0.8830\n",
      "Epoch 74/215\n",
      "390/390 [==============================] - 59s 151ms/step - loss: 0.1571 - accuracy: 0.9446 - val_loss: 0.4017 - val_accuracy: 0.8787\n",
      "Epoch 75/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.1550 - accuracy: 0.9441 - val_loss: 0.4085 - val_accuracy: 0.8720\n",
      "Epoch 76/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1544 - accuracy: 0.9449 - val_loss: 0.3945 - val_accuracy: 0.8799\n",
      "Epoch 77/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1557 - accuracy: 0.9452 - val_loss: 0.4100 - val_accuracy: 0.8753\n",
      "Epoch 78/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.1522 - accuracy: 0.9461 - val_loss: 0.4462 - val_accuracy: 0.8658\n",
      "Epoch 79/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1481 - accuracy: 0.9468 - val_loss: 0.3654 - val_accuracy: 0.8895\n",
      "Epoch 80/215\n",
      "390/390 [==============================] - 63s 160ms/step - loss: 0.1518 - accuracy: 0.9472 - val_loss: 0.4324 - val_accuracy: 0.8687\n",
      "Epoch 81/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1478 - accuracy: 0.9475 - val_loss: 0.4692 - val_accuracy: 0.8630\n",
      "Epoch 82/215\n",
      "390/390 [==============================] - 60s 155ms/step - loss: 0.1444 - accuracy: 0.9489 - val_loss: 0.3772 - val_accuracy: 0.8839\n",
      "Epoch 83/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.1449 - accuracy: 0.9490 - val_loss: 0.4157 - val_accuracy: 0.8768\n",
      "Epoch 84/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1439 - accuracy: 0.9487 - val_loss: 0.4107 - val_accuracy: 0.8743\n",
      "Epoch 85/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1410 - accuracy: 0.9506 - val_loss: 0.4017 - val_accuracy: 0.8754\n",
      "Epoch 86/215\n",
      "390/390 [==============================] - 63s 161ms/step - loss: 0.1399 - accuracy: 0.9509 - val_loss: 0.3834 - val_accuracy: 0.8834\n",
      "Epoch 87/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1409 - accuracy: 0.9502 - val_loss: 0.4568 - val_accuracy: 0.8670\n",
      "Epoch 88/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.1372 - accuracy: 0.9513 - val_loss: 0.4492 - val_accuracy: 0.8677\n",
      "Epoch 89/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1316 - accuracy: 0.9529 - val_loss: 0.4751 - val_accuracy: 0.8671\n",
      "Epoch 90/215\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.1357 - accuracy: 0.9518 - val_loss: 0.4535 - val_accuracy: 0.8630\n",
      "Epoch 91/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1343 - accuracy: 0.9525 - val_loss: 0.4619 - val_accuracy: 0.8698\n",
      "Epoch 92/215\n",
      "390/390 [==============================] - 59s 151ms/step - loss: 0.1334 - accuracy: 0.9527 - val_loss: 0.4298 - val_accuracy: 0.8731\n",
      "Epoch 93/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1318 - accuracy: 0.9532 - val_loss: 0.4279 - val_accuracy: 0.8773\n",
      "Epoch 94/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1314 - accuracy: 0.9540 - val_loss: 0.3619 - val_accuracy: 0.8904\n",
      "Epoch 95/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1274 - accuracy: 0.9547 - val_loss: 0.4013 - val_accuracy: 0.8844\n",
      "Epoch 96/215\n",
      "390/390 [==============================] - 60s 153ms/step - loss: 0.1270 - accuracy: 0.9558 - val_loss: 0.4055 - val_accuracy: 0.8763\n",
      "Epoch 97/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.1257 - accuracy: 0.9564 - val_loss: 0.5222 - val_accuracy: 0.8538\n",
      "Epoch 98/215\n",
      "390/390 [==============================] - 62s 159ms/step - loss: 0.1264 - accuracy: 0.9554 - val_loss: 0.5606 - val_accuracy: 0.8439\n",
      "Epoch 99/215\n",
      "390/390 [==============================] - 62s 160ms/step - loss: 0.1217 - accuracy: 0.9566 - val_loss: 0.3590 - val_accuracy: 0.8942\n",
      "Epoch 100/215\n",
      "390/390 [==============================] - 60s 152ms/step - loss: 0.1227 - accuracy: 0.9567 - val_loss: 0.3833 - val_accuracy: 0.8869\n",
      "Epoch 101/215\n",
      "390/390 [==============================] - 59s 152ms/step - loss: 0.1221 - accuracy: 0.9570 - val_loss: 0.4059 - val_accuracy: 0.8804\n",
      "Epoch 102/215\n",
      "390/390 [==============================] - 58s 150ms/step - loss: 0.1203 - accuracy: 0.9570 - val_loss: 0.3937 - val_accuracy: 0.8832\n",
      "Epoch 103/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.1218 - accuracy: 0.9564 - val_loss: 0.4214 - val_accuracy: 0.8776\n",
      "Epoch 104/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1227 - accuracy: 0.9561 - val_loss: 0.5126 - val_accuracy: 0.8598\n",
      "Epoch 105/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.1169 - accuracy: 0.9583 - val_loss: 0.4542 - val_accuracy: 0.8737\n",
      "Epoch 106/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1188 - accuracy: 0.9565 - val_loss: 0.4535 - val_accuracy: 0.8711\n",
      "Epoch 107/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.1185 - accuracy: 0.9575 - val_loss: 0.3939 - val_accuracy: 0.8855\n",
      "Epoch 108/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1143 - accuracy: 0.9606 - val_loss: 0.3809 - val_accuracy: 0.8884\n",
      "Epoch 109/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1194 - accuracy: 0.9579 - val_loss: 0.4804 - val_accuracy: 0.8666\n",
      "Epoch 110/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1178 - accuracy: 0.9583 - val_loss: 0.4430 - val_accuracy: 0.8747\n",
      "Epoch 111/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.1118 - accuracy: 0.9611 - val_loss: 0.3949 - val_accuracy: 0.8853\n",
      "Epoch 112/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.1141 - accuracy: 0.9602 - val_loss: 0.4224 - val_accuracy: 0.8818\n",
      "Epoch 113/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1096 - accuracy: 0.9608 - val_loss: 0.4392 - val_accuracy: 0.8776\n",
      "Epoch 114/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1071 - accuracy: 0.9619 - val_loss: 0.4016 - val_accuracy: 0.8838\n",
      "Epoch 115/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.1113 - accuracy: 0.9618 - val_loss: 0.3738 - val_accuracy: 0.8886\n",
      "Epoch 116/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.1100 - accuracy: 0.9612 - val_loss: 0.4059 - val_accuracy: 0.8834\n",
      "Epoch 117/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.1081 - accuracy: 0.9614 - val_loss: 0.4670 - val_accuracy: 0.8710\n",
      "Epoch 118/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.1107 - accuracy: 0.9615 - val_loss: 0.3826 - val_accuracy: 0.8899\n",
      "Epoch 119/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1085 - accuracy: 0.9620 - val_loss: 0.4265 - val_accuracy: 0.8794\n",
      "Epoch 120/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1068 - accuracy: 0.9623 - val_loss: 0.4196 - val_accuracy: 0.8787\n",
      "Epoch 121/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1030 - accuracy: 0.9641 - val_loss: 0.4158 - val_accuracy: 0.8858\n",
      "Epoch 122/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.1059 - accuracy: 0.9629 - val_loss: 0.3951 - val_accuracy: 0.8857\n",
      "Epoch 123/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.1014 - accuracy: 0.9636 - val_loss: 0.4813 - val_accuracy: 0.8741\n",
      "Epoch 124/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.1069 - accuracy: 0.9630 - val_loss: 0.5631 - val_accuracy: 0.8519\n",
      "Epoch 125/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1011 - accuracy: 0.9645 - val_loss: 0.4097 - val_accuracy: 0.8857\n",
      "Epoch 126/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.1018 - accuracy: 0.9636 - val_loss: 0.4319 - val_accuracy: 0.8774\n",
      "Epoch 127/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.1008 - accuracy: 0.9639 - val_loss: 0.4153 - val_accuracy: 0.8872\n",
      "Epoch 128/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.1003 - accuracy: 0.9645 - val_loss: 0.3966 - val_accuracy: 0.8874\n",
      "Epoch 129/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.1015 - accuracy: 0.9645 - val_loss: 0.4102 - val_accuracy: 0.8863\n",
      "Epoch 130/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0991 - accuracy: 0.9643 - val_loss: 0.4128 - val_accuracy: 0.8840\n",
      "Epoch 131/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.0979 - accuracy: 0.9649 - val_loss: 0.3834 - val_accuracy: 0.8893\n",
      "Epoch 132/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0994 - accuracy: 0.9651 - val_loss: 0.3730 - val_accuracy: 0.8975\n",
      "Epoch 133/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0951 - accuracy: 0.9671 - val_loss: 0.3932 - val_accuracy: 0.8873\n",
      "Epoch 134/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0995 - accuracy: 0.9644 - val_loss: 0.4764 - val_accuracy: 0.8737\n",
      "Epoch 135/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0944 - accuracy: 0.9661 - val_loss: 0.3731 - val_accuracy: 0.8968\n",
      "Epoch 136/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.0961 - accuracy: 0.9658 - val_loss: 0.3973 - val_accuracy: 0.8872\n",
      "Epoch 137/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0975 - accuracy: 0.9659 - val_loss: 0.3947 - val_accuracy: 0.8924\n",
      "Epoch 138/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0965 - accuracy: 0.9662 - val_loss: 0.3748 - val_accuracy: 0.8945\n",
      "Epoch 139/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0918 - accuracy: 0.9681 - val_loss: 0.4720 - val_accuracy: 0.8801\n",
      "Epoch 140/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0920 - accuracy: 0.9672 - val_loss: 0.4628 - val_accuracy: 0.8787\n",
      "Epoch 141/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0892 - accuracy: 0.9676 - val_loss: 0.4136 - val_accuracy: 0.8871\n",
      "Epoch 142/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0909 - accuracy: 0.9674 - val_loss: 0.3867 - val_accuracy: 0.8932\n",
      "Epoch 143/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0948 - accuracy: 0.9668 - val_loss: 0.3799 - val_accuracy: 0.8957\n",
      "Epoch 144/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0885 - accuracy: 0.9687 - val_loss: 0.3799 - val_accuracy: 0.8942\n",
      "Epoch 145/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0881 - accuracy: 0.9698 - val_loss: 0.4427 - val_accuracy: 0.8804\n",
      "Epoch 146/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0916 - accuracy: 0.9683 - val_loss: 0.5087 - val_accuracy: 0.8744\n",
      "Epoch 147/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0902 - accuracy: 0.9678 - val_loss: 0.4143 - val_accuracy: 0.8875\n",
      "Epoch 148/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0856 - accuracy: 0.9698 - val_loss: 0.3938 - val_accuracy: 0.8911\n",
      "Epoch 149/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.0911 - accuracy: 0.9679 - val_loss: 0.4480 - val_accuracy: 0.8851\n",
      "Epoch 150/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0846 - accuracy: 0.9703 - val_loss: 0.4188 - val_accuracy: 0.8862\n",
      "Epoch 151/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0841 - accuracy: 0.9707 - val_loss: 0.3686 - val_accuracy: 0.8942\n",
      "Epoch 152/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0896 - accuracy: 0.9672 - val_loss: 0.5217 - val_accuracy: 0.8614\n",
      "Epoch 153/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0883 - accuracy: 0.9690 - val_loss: 0.4257 - val_accuracy: 0.8840\n",
      "Epoch 154/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0868 - accuracy: 0.9698 - val_loss: 0.4022 - val_accuracy: 0.8942\n",
      "Epoch 155/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0846 - accuracy: 0.9705 - val_loss: 0.3813 - val_accuracy: 0.8978\n",
      "Epoch 156/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0839 - accuracy: 0.9699 - val_loss: 0.5219 - val_accuracy: 0.8676\n",
      "Epoch 157/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0828 - accuracy: 0.9710 - val_loss: 0.4972 - val_accuracy: 0.8716\n",
      "Epoch 158/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0833 - accuracy: 0.9708 - val_loss: 0.3901 - val_accuracy: 0.8925\n",
      "Epoch 159/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0832 - accuracy: 0.9719 - val_loss: 0.4537 - val_accuracy: 0.8855\n",
      "Epoch 160/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0818 - accuracy: 0.9713 - val_loss: 0.4227 - val_accuracy: 0.8852\n",
      "Epoch 161/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0826 - accuracy: 0.9710 - val_loss: 0.3968 - val_accuracy: 0.8913\n",
      "Epoch 162/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0838 - accuracy: 0.9709 - val_loss: 0.4759 - val_accuracy: 0.8783\n",
      "Epoch 163/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0832 - accuracy: 0.9707 - val_loss: 0.3881 - val_accuracy: 0.8930\n",
      "Epoch 164/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0798 - accuracy: 0.9717 - val_loss: 0.4162 - val_accuracy: 0.8909\n",
      "Epoch 165/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0783 - accuracy: 0.9725 - val_loss: 0.4416 - val_accuracy: 0.8918\n",
      "Epoch 166/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0843 - accuracy: 0.9702 - val_loss: 0.4114 - val_accuracy: 0.8882\n",
      "Epoch 167/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0844 - accuracy: 0.9693 - val_loss: 0.4383 - val_accuracy: 0.8838\n",
      "Epoch 168/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0813 - accuracy: 0.9717 - val_loss: 0.3822 - val_accuracy: 0.8954\n",
      "Epoch 169/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.4211 - val_accuracy: 0.8909\n",
      "Epoch 170/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.0779 - accuracy: 0.9727 - val_loss: 0.4250 - val_accuracy: 0.8884\n",
      "Epoch 171/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0767 - accuracy: 0.9717 - val_loss: 0.3987 - val_accuracy: 0.8956\n",
      "Epoch 172/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0800 - accuracy: 0.9719 - val_loss: 0.3962 - val_accuracy: 0.8978\n",
      "Epoch 173/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0792 - accuracy: 0.9719 - val_loss: 0.3911 - val_accuracy: 0.8954\n",
      "Epoch 174/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.0781 - accuracy: 0.9728 - val_loss: 0.3766 - val_accuracy: 0.8983\n",
      "Epoch 175/215\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 0.0773 - accuracy: 0.9730 - val_loss: 0.4518 - val_accuracy: 0.8826\n",
      "Epoch 176/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.0752 - accuracy: 0.9728 - val_loss: 0.4309 - val_accuracy: 0.8879\n",
      "Epoch 177/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0757 - accuracy: 0.9735 - val_loss: 0.4378 - val_accuracy: 0.8839\n",
      "Epoch 178/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0782 - accuracy: 0.9724 - val_loss: 0.4279 - val_accuracy: 0.8915\n",
      "Epoch 179/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0750 - accuracy: 0.9735 - val_loss: 0.4044 - val_accuracy: 0.8940\n",
      "Epoch 180/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0744 - accuracy: 0.9738 - val_loss: 0.4223 - val_accuracy: 0.8885\n",
      "Epoch 181/215\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 0.0746 - accuracy: 0.9733 - val_loss: 0.3997 - val_accuracy: 0.8970\n",
      "Epoch 182/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0755 - accuracy: 0.9739 - val_loss: 0.4042 - val_accuracy: 0.8977\n",
      "Epoch 183/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0734 - accuracy: 0.9737 - val_loss: 0.4219 - val_accuracy: 0.8852\n",
      "Epoch 184/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0746 - accuracy: 0.9735 - val_loss: 0.4130 - val_accuracy: 0.8906\n",
      "Epoch 185/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0769 - accuracy: 0.9726 - val_loss: 0.4184 - val_accuracy: 0.8943\n",
      "Epoch 186/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0711 - accuracy: 0.9755 - val_loss: 0.4362 - val_accuracy: 0.8816\n",
      "Epoch 187/215\n",
      "390/390 [==============================] - 56s 144ms/step - loss: 0.0734 - accuracy: 0.9742 - val_loss: 0.3914 - val_accuracy: 0.8946\n",
      "Epoch 188/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0713 - accuracy: 0.9750 - val_loss: 0.3908 - val_accuracy: 0.8961\n",
      "Epoch 189/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0704 - accuracy: 0.9748 - val_loss: 0.3824 - val_accuracy: 0.8993\n",
      "Epoch 190/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.0702 - accuracy: 0.9758 - val_loss: 0.4434 - val_accuracy: 0.8803\n",
      "Epoch 191/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0713 - accuracy: 0.9749 - val_loss: 0.4615 - val_accuracy: 0.8830\n",
      "Epoch 192/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0692 - accuracy: 0.9752 - val_loss: 0.4076 - val_accuracy: 0.8968\n",
      "Epoch 193/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.0710 - accuracy: 0.9746 - val_loss: 0.4099 - val_accuracy: 0.8984\n",
      "Epoch 194/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0739 - accuracy: 0.9740 - val_loss: 0.4153 - val_accuracy: 0.8916\n",
      "Epoch 195/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0683 - accuracy: 0.9764 - val_loss: 0.4480 - val_accuracy: 0.8858\n",
      "Epoch 196/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0718 - accuracy: 0.9753 - val_loss: 0.4026 - val_accuracy: 0.8999\n",
      "Epoch 197/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0652 - accuracy: 0.9772 - val_loss: 0.4002 - val_accuracy: 0.8952\n",
      "Epoch 198/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.0691 - accuracy: 0.9755 - val_loss: 0.4120 - val_accuracy: 0.8944\n",
      "Epoch 199/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0703 - accuracy: 0.9748 - val_loss: 0.4804 - val_accuracy: 0.8845\n",
      "Epoch 200/215\n",
      "390/390 [==============================] - 61s 156ms/step - loss: 0.0701 - accuracy: 0.9753 - val_loss: 0.3979 - val_accuracy: 0.8985\n",
      "Epoch 201/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0679 - accuracy: 0.9765 - val_loss: 0.4085 - val_accuracy: 0.8939\n",
      "Epoch 202/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0702 - accuracy: 0.9748 - val_loss: 0.4225 - val_accuracy: 0.8980\n",
      "Epoch 203/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0668 - accuracy: 0.9768 - val_loss: 0.4266 - val_accuracy: 0.8923\n",
      "Epoch 204/215\n",
      "390/390 [==============================] - 57s 145ms/step - loss: 0.0671 - accuracy: 0.9770 - val_loss: 0.4112 - val_accuracy: 0.8951\n",
      "Epoch 205/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0685 - accuracy: 0.9756 - val_loss: 0.3746 - val_accuracy: 0.9023\n",
      "Epoch 206/215\n",
      "390/390 [==============================] - 58s 147ms/step - loss: 0.0652 - accuracy: 0.9776 - val_loss: 0.4139 - val_accuracy: 0.8928\n",
      "Epoch 207/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0632 - accuracy: 0.9775 - val_loss: 0.3831 - val_accuracy: 0.9012\n",
      "Epoch 208/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0652 - accuracy: 0.9769 - val_loss: 0.4401 - val_accuracy: 0.8877\n",
      "Epoch 209/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.4009 - val_accuracy: 0.8956\n",
      "Epoch 210/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0691 - accuracy: 0.9765 - val_loss: 0.4280 - val_accuracy: 0.8941\n",
      "Epoch 211/215\n",
      "390/390 [==============================] - 57s 147ms/step - loss: 0.0672 - accuracy: 0.9766 - val_loss: 0.4124 - val_accuracy: 0.8947\n",
      "Epoch 212/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0666 - accuracy: 0.9772 - val_loss: 0.5283 - val_accuracy: 0.8751\n",
      "Epoch 213/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0672 - accuracy: 0.9757 - val_loss: 0.3979 - val_accuracy: 0.8991\n",
      "Epoch 214/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0654 - accuracy: 0.9771 - val_loss: 0.4335 - val_accuracy: 0.8899\n",
      "Epoch 215/215\n",
      "390/390 [==============================] - 57s 146ms/step - loss: 0.0643 - accuracy: 0.9772 - val_loss: 0.4102 - val_accuracy: 0.8975\n"
     ]
    }
   ],
   "source": [
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                 validation_data=datagen.flow(X_test, y_test),\n",
    "                 steps_per_epoch=len(X_train) / 128, epochs=215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T13:02:35.666976Z",
     "iopub.status.busy": "2022-12-08T13:02:35.666208Z",
     "iopub.status.idle": "2022-12-08T13:02:35.927704Z",
     "shell.execute_reply": "2022-12-08T13:02:35.926709Z",
     "shell.execute_reply.started": "2022-12-08T13:02:35.666936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T13:03:30.236472Z",
     "iopub.status.busy": "2022-12-08T13:03:30.236075Z",
     "iopub.status.idle": "2022-12-08T13:03:30.435725Z",
     "shell.execute_reply": "2022-12-08T13:03:30.434856Z",
     "shell.execute_reply.started": "2022-12-08T13:03:30.236440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T13:05:40.282373Z",
     "iopub.status.busy": "2022-12-08T13:05:40.281991Z",
     "iopub.status.idle": "2022-12-08T13:05:40.288665Z",
     "shell.execute_reply": "2022-12-08T13:05:40.287705Z",
     "shell.execute_reply.started": "2022-12-08T13:05:40.282334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.9023000001907349\n"
     ]
    }
   ],
   "source": [
    "res = history.history['val_accuracy']\n",
    "val_accuracy = max(res)\n",
    "\n",
    "print('Validation Accuracy: ', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T13:18:10.508471Z",
     "iopub.status.busy": "2022-12-08T13:18:10.508068Z",
     "iopub.status.idle": "2022-12-08T13:18:10.514574Z",
     "shell.execute_reply": "2022-12-08T13:18:10.513258Z",
     "shell.execute_reply.started": "2022-12-08T13:18:10.508437Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T13:18:12.416723Z",
     "iopub.status.busy": "2022-12-08T13:18:12.415874Z",
     "iopub.status.idle": "2022-12-08T13:18:17.940222Z",
     "shell.execute_reply": "2022-12-08T13:18:17.939238Z",
     "shell.execute_reply.started": "2022-12-08T13:18:12.416677Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = np.argmax(model.predict(X_test),axis=1)\n",
    "\n",
    "y = np.argmax(y_test, axis=1)\n",
    "cm = tf.math.confusion_matrix(labels=y, predictions=y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-08T13:18:21.939101Z",
     "iopub.status.busy": "2022-12-08T13:18:21.938721Z",
     "iopub.status.idle": "2022-12-08T13:18:21.969902Z",
     "shell.execute_reply": "2022-12-08T13:18:21.968915Z",
     "shell.execute_reply.started": "2022-12-08T13:18:21.939071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            airplane  automobile  bird  cat  deer  dog  frog  horse  ship  \\\n",
      "airplane         911          14     4    3     3    0     1      1    33   \n",
      "automobile         0         980     1    0     0    0     0      0     1   \n",
      "bird              31          13   885   10    13    7    21      5     8   \n",
      "cat               17          18    24  809    27   37    30      6     9   \n",
      "deer               7           6    34    6   913    3    16     10     2   \n",
      "dog                7          19    27   94    20  784    23     13     2   \n",
      "frog               5           9    13    7     3    0   954      0     4   \n",
      "horse              7           9     8    5    24   16     6    918     1   \n",
      "ship              20          15     2    1     0    0     1      0   941   \n",
      "truck              4          46     0    0     0    0     0      0     7   \n",
      "\n",
      "            truck  \n",
      "airplane       30  \n",
      "automobile     18  \n",
      "bird            7  \n",
      "cat            23  \n",
      "deer            3  \n",
      "dog            11  \n",
      "frog            5  \n",
      "horse           6  \n",
      "ship           20  \n",
      "truck         943  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "con_mat_df = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "print(con_mat_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN on CIFR Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
