{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwPL0hIlGKoA"
   },
   "source": [
    "# <font color='red'>**Sequence to sequence implementation**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvNSZXNkkOkO"
   },
   "source": [
    "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
    "\n",
    "2. You will find **ita.txt** file in that ZIP, \n",
    "you can read that data using python and preprocess that data this way only: \n",
    "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
    "    \n",
    "3. Implement a simple Encoder and Decoder architecture  \n",
    "\n",
    "4.  BLEU score as metric to evaluate your model.\n",
    "\n",
    "5. Use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:06:44.606320Z",
     "iopub.status.busy": "2023-01-24T12:06:44.605869Z",
     "iopub.status.idle": "2023-01-24T12:06:50.781640Z",
     "shell.execute_reply": "2023-01-24T12:06:50.780722Z",
     "shell.execute_reply.started": "2023-01-24T12:06:44.606241Z"
    },
    "id": "Nirk8Q8IlfgW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k_AlAuKJqVA"
   },
   "source": [
    "<font color='blue'>**Load the data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:06:57.933022Z",
     "iopub.status.busy": "2023-01-24T12:06:57.931715Z",
     "iopub.status.idle": "2023-01-24T12:07:00.618975Z",
     "shell.execute_reply": "2023-01-24T12:07:00.617747Z",
     "shell.execute_reply.started": "2023-01-24T12:06:57.932975Z"
    },
    "id": "fU80Ao-AGaob",
    "outputId": "ee41ed7d-fce6-4ce7-82cb-7c50a3dbdd96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-24 12:06:58--  http://www.manythings.org/anki/ita-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7882203 (7.5M) [application/zip]\n",
      "Saving to: ‘ita-eng.zip’\n",
      "\n",
      "ita-eng.zip         100%[===================>]   7.52M  6.42MB/s    in 1.2s    \n",
      "\n",
      "2023-01-24 12:07:00 (6.42 MB/s) - ‘ita-eng.zip’ saved [7882203/7882203]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/ita-eng.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:07:04.615423Z",
     "iopub.status.busy": "2023-01-24T12:07:04.615036Z",
     "iopub.status.idle": "2023-01-24T12:07:05.873638Z",
     "shell.execute_reply": "2023-01-24T12:07:05.872480Z",
     "shell.execute_reply.started": "2023-01-24T12:07:04.615388Z"
    },
    "id": "BCj1KriwtYFs",
    "outputId": "bc943e38-1067-414f-8efb-f605280e10c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ita-eng.zip\n",
      "  inflating: ita.txt                 \n",
      "  inflating: _about.txt              \n"
     ]
    }
   ],
   "source": [
    "!unzip ita-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmGWTdRmKRph"
   },
   "source": [
    "<font color='blue'>**Preprocess data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:04.882535Z",
     "iopub.status.busy": "2023-01-24T12:08:04.881796Z",
     "iopub.status.idle": "2023-01-24T12:08:20.105166Z",
     "shell.execute_reply": "2023-01-24T12:08:20.104004Z",
     "shell.execute_reply.started": "2023-01-24T12:08:04.882497Z"
    },
    "id": "9QqElB_nKZos",
    "outputId": "5682494b-a219-4a44-804d-8891b8967fa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-24 12:08:05--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.18, 2620:100:601f:18::a27d:912\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
      "--2023-01-24 12:08:06--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc06ebfdd2bf037f97d3ff634656.dl.dropboxusercontent.com/cd/0/inline/B1LTVHkvIsIdpuJpK4J2ecQd8GxzCOVE3QzLi9RSKQNw4v7Xa1jzbhoK1du68V7Di5Ok17R00XzXibZCKTisEy1jmshtSktaiyJF-S8lMVoLGTFgeyNc99TEIqYbb24KAWqj6j1UaLL4_ajI12n-LEBu8utbg_KUQhRtJ4qGxGnxUw/file# [following]\n",
      "--2023-01-24 12:08:07--  https://uc06ebfdd2bf037f97d3ff634656.dl.dropboxusercontent.com/cd/0/inline/B1LTVHkvIsIdpuJpK4J2ecQd8GxzCOVE3QzLi9RSKQNw4v7Xa1jzbhoK1du68V7Di5Ok17R00XzXibZCKTisEy1jmshtSktaiyJF-S8lMVoLGTFgeyNc99TEIqYbb24KAWqj6j1UaLL4_ajI12n-LEBu8utbg_KUQhRtJ4qGxGnxUw/file\n",
      "Resolving uc06ebfdd2bf037f97d3ff634656.dl.dropboxusercontent.com (uc06ebfdd2bf037f97d3ff634656.dl.dropboxusercontent.com)... 162.125.9.15, 2620:100:601f:15::a27d:90f\n",
      "Connecting to uc06ebfdd2bf037f97d3ff634656.dl.dropboxusercontent.com (uc06ebfdd2bf037f97d3ff634656.dl.dropboxusercontent.com)|162.125.9.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 347116733 (331M) [text/plain]\n",
      "Saving to: ‘glove.6B.100d.txt’\n",
      "\n",
      "glove.6B.100d.txt   100%[===================>] 331.04M  30.9MB/s    in 11s     \n",
      "\n",
      "2023-01-24 12:08:19 (29.3 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:23.471337Z",
     "iopub.status.busy": "2023-01-24T12:08:23.470938Z",
     "iopub.status.idle": "2023-01-24T12:08:24.147786Z",
     "shell.execute_reply": "2023-01-24T12:08:24.146722Z",
     "shell.execute_reply.started": "2023-01-24T12:08:23.471302Z"
    },
    "id": "YvfwFa7c9iQq",
    "outputId": "7df2406f-1e38-4baf-ff2f-f4c60f8ff95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358373, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   italian\n",
       "0     Hi.     Ciao!\n",
       "1     Hi.     Ciao.\n",
       "2    Run!    Corri!\n",
       "3    Run!    Corra!\n",
       "4    Run!  Correte!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
    "    eng=[]\n",
    "    ita=[]\n",
    "    for i in f.readlines():\n",
    "        eng.append(i.split(\"\\t\")[0])\n",
    "        ita.append(i.split(\"\\t\")[1])\n",
    "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:30.118630Z",
     "iopub.status.busy": "2023-01-24T12:08:30.118252Z",
     "iopub.status.idle": "2023-01-24T12:08:46.589543Z",
     "shell.execute_reply": "2023-01-24T12:08:46.588551Z",
     "shell.execute_reply.started": "2023-01-24T12:08:30.118597Z"
    },
    "id": "sH4Tfl3g9lRB",
    "outputId": "db4372b8-741f-4ad4-c9e3-db6b0c2fd0e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>ciao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>ciao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>corri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>corra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run</td>\n",
       "      <td>correte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english  italian\n",
       "0      hi     ciao\n",
       "1      hi     ciao\n",
       "2     run    corri\n",
       "3     run    corra\n",
       "4     run  correte"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decontractions(phrase):\n",
    "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    # convert all the text into lower letters\n",
    "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
    "    # remove all the spacial characters: except space ' '\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_ita(text):\n",
    "    # convert all the text into lower letters\n",
    "    # remove the words betweent brakets ()\n",
    "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
    "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
    "    # I have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
    "    # you are free to do more proprocessing\n",
    "    # note that the model will learn better with better preprocessed data \n",
    "    \n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
    "    text = re.sub('\\u200b', ' ', text)\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    text = re.sub('-', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "data['english'] = data['english'].apply(preprocess)\n",
    "data['italian'] = data['italian'].apply(preprocess_ita)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:46.592268Z",
     "iopub.status.busy": "2023-01-24T12:08:46.591646Z",
     "iopub.status.idle": "2023-01-24T12:08:48.707779Z",
     "shell.execute_reply": "2023-01-24T12:08:48.706651Z",
     "shell.execute_reply.started": "2023-01-24T12:08:46.592231Z"
    },
    "id": "ESNcDx9f914L",
    "outputId": "d774b926-2519-4abf-9ed0-b0246ebf5a6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corri</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corra</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>correte</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   italian  english_inp english_out\n",
       "0     ciao   <start> hi    hi <end>\n",
       "1     ciao   <start> hi    hi <end>\n",
       "2    corri  <start> run   run <end>\n",
       "3    corra  <start> run   run <end>\n",
       "4  correte  <start> run   run <end>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['italian_len'] = data['italian'].str.split().apply(len)\n",
    "data = data[data['italian_len'] < 20]\n",
    "\n",
    "data['english_len'] = data['english'].str.split().apply(len)\n",
    "data = data[data['english_len'] < 20]\n",
    "\n",
    "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
    "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
    "\n",
    "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:48.709970Z",
     "iopub.status.busy": "2023-01-24T12:08:48.709337Z",
     "iopub.status.idle": "2023-01-24T12:08:48.732119Z",
     "shell.execute_reply": "2023-01-24T12:08:48.731262Z",
     "shell.execute_reply.started": "2023-01-24T12:08:48.709931Z"
    },
    "id": "yxouecbE93RR",
    "outputId": "e7ba735c-daac-4872-ad4a-1bf70be22c6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214463</th>\n",
       "      <td>unape volò fuori dalla finestra</td>\n",
       "      <td>&lt;start&gt; a bee flew out of the window</td>\n",
       "      <td>a bee flew out of the window &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221718</th>\n",
       "      <td>fammi sapere il tuo nuovo indirizzo</td>\n",
       "      <td>&lt;start&gt; let me know your new address</td>\n",
       "      <td>let me know your new address &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97099</th>\n",
       "      <td>tom ha finito il lavoro</td>\n",
       "      <td>&lt;start&gt; tom finished the job</td>\n",
       "      <td>tom finished the job &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357118</th>\n",
       "      <td>tom ha comprato una macchina fotografica un pa...</td>\n",
       "      <td>&lt;start&gt; tom bought a camera just a couple of d...</td>\n",
       "      <td>tom bought a camera just a couple of days ago ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130557</th>\n",
       "      <td>noi conoscevamo entrambi i rischi</td>\n",
       "      <td>&lt;start&gt; we both knew the risks</td>\n",
       "      <td>we both knew the risks &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114140</th>\n",
       "      <td>tom viveva qui</td>\n",
       "      <td>&lt;start&gt; tom used to live here</td>\n",
       "      <td>tom used to live here &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186275</th>\n",
       "      <td>ho sentito che è venuta qui</td>\n",
       "      <td>&lt;start&gt; i heard that she came here</td>\n",
       "      <td>i heard that she came here &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341221</th>\n",
       "      <td>pensavo che sarei arrivata qui prima di voi</td>\n",
       "      <td>&lt;start&gt; i thought i was going to get here befo...</td>\n",
       "      <td>i thought i was going to get here before you &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22618</th>\n",
       "      <td>tom sta canticchiando</td>\n",
       "      <td>&lt;start&gt; tom is humming</td>\n",
       "      <td>tom is humming &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279973</th>\n",
       "      <td>voi siete superficiali e materialisti</td>\n",
       "      <td>&lt;start&gt; you are shallow and materialistic</td>\n",
       "      <td>you are shallow and materialistic &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  italian  \\\n",
       "214463                    unape volò fuori dalla finestra   \n",
       "221718                fammi sapere il tuo nuovo indirizzo   \n",
       "97099                             tom ha finito il lavoro   \n",
       "357118  tom ha comprato una macchina fotografica un pa...   \n",
       "130557                  noi conoscevamo entrambi i rischi   \n",
       "114140                                     tom viveva qui   \n",
       "186275                        ho sentito che è venuta qui   \n",
       "341221        pensavo che sarei arrivata qui prima di voi   \n",
       "22618                               tom sta canticchiando   \n",
       "279973              voi siete superficiali e materialisti   \n",
       "\n",
       "                                              english_inp  \\\n",
       "214463               <start> a bee flew out of the window   \n",
       "221718               <start> let me know your new address   \n",
       "97099                        <start> tom finished the job   \n",
       "357118  <start> tom bought a camera just a couple of d...   \n",
       "130557                     <start> we both knew the risks   \n",
       "114140                      <start> tom used to live here   \n",
       "186275                 <start> i heard that she came here   \n",
       "341221  <start> i thought i was going to get here befo...   \n",
       "22618                              <start> tom is humming   \n",
       "279973          <start> you are shallow and materialistic   \n",
       "\n",
       "                                              english_out  \n",
       "214463                 a bee flew out of the window <end>  \n",
       "221718                 let me know your new address <end>  \n",
       "97099                          tom finished the job <end>  \n",
       "357118  tom bought a camera just a couple of days ago ...  \n",
       "130557                       we both knew the risks <end>  \n",
       "114140                        tom used to live here <end>  \n",
       "186275                   i heard that she came here <end>  \n",
       "341221  i thought i was going to get here before you <...  \n",
       "22618                                tom is humming <end>  \n",
       "279973            you are shallow and materialistic <end>  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:48.735485Z",
     "iopub.status.busy": "2023-01-24T12:08:48.735214Z",
     "iopub.status.idle": "2023-01-24T12:08:48.896143Z",
     "shell.execute_reply": "2023-01-24T12:08:48.895171Z",
     "shell.execute_reply.started": "2023-01-24T12:08:48.735459Z"
    },
    "id": "za1AkanJ-uKa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:50.621507Z",
     "iopub.status.busy": "2023-01-24T12:08:50.621123Z",
     "iopub.status.idle": "2023-01-24T12:08:50.627319Z",
     "shell.execute_reply": "2023-01-24T12:08:50.626150Z",
     "shell.execute_reply.started": "2023-01-24T12:08:50.621475Z"
    },
    "id": "nZenBqVPyiuj",
    "outputId": "a023ea85-bbfe-4f04-e57e-57ae82c36fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286292, 3) (71574, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:53.391388Z",
     "iopub.status.busy": "2023-01-24T12:08:53.391006Z",
     "iopub.status.idle": "2023-01-24T12:08:53.397404Z",
     "shell.execute_reply": "2023-01-24T12:08:53.396262Z",
     "shell.execute_reply.started": "2023-01-24T12:08:53.391357Z"
    },
    "id": "dlpK1NkZ-vHb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# for one sentence I will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this I can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
    "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:55.071663Z",
     "iopub.status.busy": "2023-01-24T12:08:55.071287Z",
     "iopub.status.idle": "2023-01-24T12:08:55.084513Z",
     "shell.execute_reply": "2023-01-24T12:08:55.083344Z",
     "shell.execute_reply.started": "2023-01-24T12:08:55.071629Z"
    },
    "id": "u0HvbffU-wxl",
    "outputId": "9b18122f-1316-4d88-9499-07ed6f16c405"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169218</th>\n",
       "      <td>come vorreste pagare</td>\n",
       "      <td>&lt;start&gt; how would you like to pay &lt;end&gt;</td>\n",
       "      <td>how would you like to pay &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133514</th>\n",
       "      <td>voi non siete male in questo</td>\n",
       "      <td>&lt;start&gt; you are not bad at this</td>\n",
       "      <td>you are not bad at this &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281720</th>\n",
       "      <td>suo fratello va a scuola in autobus</td>\n",
       "      <td>&lt;start&gt; her brother goes to school by bus</td>\n",
       "      <td>her brother goes to school by bus &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157073</th>\n",
       "      <td>sono così felice che voi siate qui</td>\n",
       "      <td>&lt;start&gt; i am so happy you are here</td>\n",
       "      <td>i am so happy you are here &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219338</th>\n",
       "      <td>non mi sarei dovuta fidare di tom</td>\n",
       "      <td>&lt;start&gt; i should not have trusted tom</td>\n",
       "      <td>i should not have trusted tom &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152154</th>\n",
       "      <td>mi diede diversi libri</td>\n",
       "      <td>&lt;start&gt; he gave me several books</td>\n",
       "      <td>he gave me several books &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118314</th>\n",
       "      <td>potete portarmi da tom</td>\n",
       "      <td>&lt;start&gt; can you take me to tom</td>\n",
       "      <td>can you take me to tom &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222387</th>\n",
       "      <td>in questo momento la gente è spaventata</td>\n",
       "      <td>&lt;start&gt; right now people are scared</td>\n",
       "      <td>right now people are scared &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328200</th>\n",
       "      <td>fece del duro lavoro manuale durante il giorno</td>\n",
       "      <td>&lt;start&gt; he did hard manual labor through the day</td>\n",
       "      <td>he did hard manual labor through the day &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95552</th>\n",
       "      <td>mi ha aiutata molto</td>\n",
       "      <td>&lt;start&gt; that helped me a lot</td>\n",
       "      <td>that helped me a lot &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               italian  \\\n",
       "169218                            come vorreste pagare   \n",
       "133514                    voi non siete male in questo   \n",
       "281720             suo fratello va a scuola in autobus   \n",
       "157073              sono così felice che voi siate qui   \n",
       "219338               non mi sarei dovuta fidare di tom   \n",
       "152154                          mi diede diversi libri   \n",
       "118314                          potete portarmi da tom   \n",
       "222387         in questo momento la gente è spaventata   \n",
       "328200  fece del duro lavoro manuale durante il giorno   \n",
       "95552                              mi ha aiutata molto   \n",
       "\n",
       "                                             english_inp  \\\n",
       "169218           <start> how would you like to pay <end>   \n",
       "133514                   <start> you are not bad at this   \n",
       "281720         <start> her brother goes to school by bus   \n",
       "157073                <start> i am so happy you are here   \n",
       "219338             <start> i should not have trusted tom   \n",
       "152154                  <start> he gave me several books   \n",
       "118314                    <start> can you take me to tom   \n",
       "222387               <start> right now people are scared   \n",
       "328200  <start> he did hard manual labor through the day   \n",
       "95552                       <start> that helped me a lot   \n",
       "\n",
       "                                           english_out  \n",
       "169218           how would you like to pay <end> <end>  \n",
       "133514                   you are not bad at this <end>  \n",
       "281720         her brother goes to school by bus <end>  \n",
       "157073                i am so happy you are here <end>  \n",
       "219338             i should not have trusted tom <end>  \n",
       "152154                  he gave me several books <end>  \n",
       "118314                    can you take me to tom <end>  \n",
       "222387               right now people are scared <end>  \n",
       "328200  he did hard manual labor through the day <end>  \n",
       "95552                       that helped me a lot <end>  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:08:56.488291Z",
     "iopub.status.busy": "2023-01-24T12:08:56.487928Z",
     "iopub.status.idle": "2023-01-24T12:09:00.928535Z",
     "shell.execute_reply": "2023-01-24T12:09:00.927625Z",
     "shell.execute_reply.started": "2023-01-24T12:08:56.488260Z"
    },
    "id": "sjAkOfFf-y85",
    "outputId": "d1113257-0e6a-41c5-8553-aea83a92e3cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ita_lengths = train['italian'].str.split().apply(len)\n",
    "eng_lengths = train['english_inp'].str.split().apply(len)\n",
    "import seaborn as sns\n",
    "sns.kdeplot(ita_lengths)\n",
    "plt.show()\n",
    "sns.kdeplot(eng_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8RDrP4xKabR"
   },
   "source": [
    "## <font color='blue'>**Implement custom encoder decoder**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A45uc0JILMlV"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:04.970864Z",
     "iopub.status.busy": "2023-01-24T12:09:04.970489Z",
     "iopub.status.idle": "2023-01-24T12:09:11.500268Z",
     "shell.execute_reply": "2023-01-24T12:09:11.499184Z",
     "shell.execute_reply.started": "2023-01-24T12:09:04.970833Z"
    },
    "id": "7T7ehBs--p_T"
   },
   "outputs": [],
   "source": [
    "tknizer_ita = Tokenizer()\n",
    "tknizer_ita.fit_on_texts(train['italian'].values)\n",
    "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_eng.fit_on_texts(train['english_inp'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:11.502828Z",
     "iopub.status.busy": "2023-01-24T12:09:11.502375Z",
     "iopub.status.idle": "2023-01-24T12:09:11.509025Z",
     "shell.execute_reply": "2023-01-24T12:09:11.507872Z",
     "shell.execute_reply.started": "2023-01-24T12:09:11.502788Z"
    },
    "id": "Vac5X91s-sJr",
    "outputId": "fe32d55f-930b-4831-9279-452f30a107a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13180\n",
      "26768\n"
     ]
    }
   ],
   "source": [
    "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
    "print(vocab_size_eng)\n",
    "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
    "print(vocab_size_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:11.511084Z",
     "iopub.status.busy": "2023-01-24T12:09:11.510732Z",
     "iopub.status.idle": "2023-01-24T12:09:11.522024Z",
     "shell.execute_reply": "2023-01-24T12:09:11.520855Z",
     "shell.execute_reply.started": "2023-01-24T12:09:11.511049Z"
    },
    "id": "b_cpMsdh-4a2",
    "outputId": "4d0ab9d4-ad72-42bf-b032-70ee3f143f7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10409)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:11.525143Z",
     "iopub.status.busy": "2023-01-24T12:09:11.524800Z",
     "iopub.status.idle": "2023-01-24T12:09:19.038776Z",
     "shell.execute_reply": "2023-01-24T12:09:19.037602Z",
     "shell.execute_reply.started": "2023-01-24T12:09:11.525109Z"
    },
    "id": "k8Oe0mPE-Lrk"
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
    "for word, i in tknizer_eng.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:19.041070Z",
     "iopub.status.busy": "2023-01-24T12:09:19.040780Z",
     "iopub.status.idle": "2023-01-24T12:09:19.051713Z",
     "shell.execute_reply": "2023-01-24T12:09:19.050653Z",
     "shell.execute_reply.started": "2023-01-24T12:09:19.041045Z"
    },
    "id": "f-sB5uEE-IMV"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_dim = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_output = 0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "    \n",
    "    def call(self,input_sentances, states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        input_embedd = self.embedding(input_sentances)\n",
    "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
    "        \n",
    "        return self.lstm_output, self.lstm_state_h, self.lstm_state_c\n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "        '''\n",
    "        Given a batch size it will return intial hidden state and intial cell state.\n",
    "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "        '''\n",
    "        dim1 = tf.zeros(shape=[batch_size,self.lstm_size])\n",
    "        dim2 = tf.zeros(shape=[batch_size,self.lstm_size])\n",
    "\n",
    "        return [dim1, dim2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtbOI3VwLOe0"
   },
   "source": [
    "<font color='orange'>**Grader function - 1**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:19.054185Z",
     "iopub.status.busy": "2023-01-24T12:09:19.053512Z",
     "iopub.status.idle": "2023-01-24T12:09:22.546383Z",
     "shell.execute_reply": "2023-01-24T12:09:22.545375Z",
     "shell.execute_reply.started": "2023-01-24T12:09:19.054149Z"
    },
    "id": "ziSqOgmhLOe1",
    "outputId": "2834e337-9196-463d-8748-b316757d576e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 12:09:19.137895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:19.226777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:19.227544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:19.229290: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-24 12:09:19.229609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:19.230337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:19.230990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:21.266310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:21.267170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:21.267847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-24 12:09:21.268437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_encoder():\n",
    "    '''\n",
    "        vocab-size: Unique words of the input language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        lstm_size: Number of lstm units,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    vocab_size=10\n",
    "    embedding_size=20\n",
    "    lstm_size=32\n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    #Intialzing encoder \n",
    "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
    "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
    "    #Intializing encoder initial states\n",
    "    initial_state=encoder.initialize_states(batch_size)\n",
    "    \n",
    "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
    "    \n",
    "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
    "    return True\n",
    "print(grader_check_encoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:28.141809Z",
     "iopub.status.busy": "2023-01-24T12:09:28.141145Z",
     "iopub.status.idle": "2023-01-24T12:09:28.149982Z",
     "shell.execute_reply": "2023-01-24T12:09:28.148804Z",
     "shell.execute_reply.started": "2023-01-24T12:09:28.141770Z"
    },
    "id": "S6fNro7E_5sD"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self, out_vocab_size, embedding_dim, lstm_size, input_length):\n",
    "        super().__init__()\n",
    "        self.vocab_size = out_vocab_size\n",
    "        self.embedding_dim = 100\n",
    "        self.dec_units = lstm_size\n",
    "        self.input_length = input_length\n",
    "        # we are using embedding_matrix and not training the embedding layer\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\")\n",
    "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
    "        \n",
    "\n",
    "\n",
    "    def call(self, target_sentances, initial_state):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
    "        '''\n",
    "        target_embedd = self.embedding(target_sentances)\n",
    "        lstm_output, _,_ = self.lstm(target_embedd, initial_state)\n",
    "\n",
    "        return lstm_output, _, _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq-I0SUbLOe8"
   },
   "source": [
    "<font color='orange'>**Grader function - 2**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:30.799802Z",
     "iopub.status.busy": "2023-01-24T12:09:30.799416Z",
     "iopub.status.idle": "2023-01-24T12:09:30.839686Z",
     "shell.execute_reply": "2023-01-24T12:09:30.838261Z",
     "shell.execute_reply.started": "2023-01-24T12:09:30.799769Z"
    },
    "id": "0B0gokgKLOe8",
    "outputId": "c0309af9-0a2a-467a-927e-7424b99069ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_decoder():\n",
    "    '''\n",
    "        out_vocab_size: Unique words of the target language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    out_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    dec_units=16 \n",
    "    batch_size=32\n",
    "    \n",
    "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    states=[state_h,state_c]\n",
    "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
    "    output,_,_=decoder(target_sentences, states)\n",
    "    assert(output.shape==(batch_size,input_length,dec_units))\n",
    "    return True\n",
    "print(grader_decoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:32.390246Z",
     "iopub.status.busy": "2023-01-24T12:09:32.389541Z",
     "iopub.status.idle": "2023-01-24T12:09:32.398502Z",
     "shell.execute_reply": "2023-01-24T12:09:32.397455Z",
     "shell.execute_reply.started": "2023-01-24T12:09:32.390207Z"
    },
    "id": "BXrIj4scLOe_"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, encoder_inputs_length, decoder_inputs_length, output_vocab_size, batch_size):\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita+1, embedding_size=50, input_length=encoder_inputs_length, lstm_size=256)\n",
    "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1, embedding_dim=100, input_length=decoder_inputs_length, lstm_size=256)\n",
    "        self.dense   = Dense(output_vocab_size, activation='softmax')\n",
    "        self.initial_state = self.encoder.initialize_states(batch_size)\n",
    "\n",
    "\n",
    "    \n",
    "    def call(self,data):\n",
    "        '''\n",
    "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "        C. Pass the decoder_outputs into Dense layer \n",
    "        \n",
    "        Return decoder_outputs\n",
    "        '''\n",
    "        input,output = data[0], data[1]\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input, self.initial_state)\n",
    "        decoder_output, decoder_h, decoder_c = self.decoder(output, [encoder_h, encoder_c])\n",
    "        output = self.dense(decoder_output)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:35.340723Z",
     "iopub.status.busy": "2023-01-24T12:09:35.340342Z",
     "iopub.status.idle": "2023-01-24T12:09:35.353624Z",
     "shell.execute_reply": "2023-01-24T12:09:35.352694Z",
     "shell.execute_reply.started": "2023-01-24T12:09:35.340669Z"
    },
    "id": "TGCD58nB-eCU"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
    "        self.encoder_inps = data['italian'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tknizer_eng = tknizer_eng\n",
    "        self.tknizer_ita = tknizer_ita\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:38.217367Z",
     "iopub.status.busy": "2023-01-24T12:09:38.216997Z",
     "iopub.status.idle": "2023-01-24T12:09:38.501319Z",
     "shell.execute_reply": "2023-01-24T12:09:38.500084Z",
     "shell.execute_reply.started": "2023-01-24T12:09:38.217335Z"
    },
    "id": "vFlvl8On-gEk",
    "outputId": "a254809e-3b1a-4148-97da-dfb4d60c326f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 20) (1024, 20) (1024, 20)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 20)\n",
    "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 20)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=1024)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=1024)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:09:43.793379Z",
     "iopub.status.busy": "2023-01-24T12:09:43.793021Z",
     "iopub.status.idle": "2023-01-24T12:35:24.587598Z",
     "shell.execute_reply": "2023-01-24T12:35:24.586666Z",
     "shell.execute_reply.started": "2023-01-24T12:09:43.793349Z"
    },
    "id": "LOPM-5-KJVbE",
    "outputId": "d76a9240-5351-418d-b349-73f66bd2579c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 12:09:44.650348: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
      "2023-01-24 12:09:44.995014: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "279/279 [==============================] - 56s 177ms/step - loss: 1.8417 - val_loss: 1.6134\n",
      "Epoch 2/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 1.5026 - val_loss: 1.3806\n",
      "Epoch 3/30\n",
      "279/279 [==============================] - 49s 176ms/step - loss: 1.2915 - val_loss: 1.2044\n",
      "Epoch 4/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 1.1393 - val_loss: 1.0623\n",
      "Epoch 5/30\n",
      "279/279 [==============================] - 46s 164ms/step - loss: 1.0137 - val_loss: 0.9517\n",
      "Epoch 6/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 0.9110 - val_loss: 0.8543\n",
      "Epoch 7/30\n",
      "279/279 [==============================] - 46s 164ms/step - loss: 0.8237 - val_loss: 0.7725\n",
      "Epoch 8/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 0.7482 - val_loss: 0.7016\n",
      "Epoch 9/30\n",
      "279/279 [==============================] - 48s 171ms/step - loss: 0.6789 - val_loss: 0.6330\n",
      "Epoch 10/30\n",
      "279/279 [==============================] - 48s 171ms/step - loss: 0.6148 - val_loss: 0.5715\n",
      "Epoch 11/30\n",
      "279/279 [==============================] - 49s 174ms/step - loss: 0.5550 - val_loss: 0.5129\n",
      "Epoch 12/30\n",
      "279/279 [==============================] - 46s 163ms/step - loss: 0.5012 - val_loss: 0.4647\n",
      "Epoch 13/30\n",
      "279/279 [==============================] - 49s 174ms/step - loss: 0.4529 - val_loss: 0.4174\n",
      "Epoch 14/30\n",
      "279/279 [==============================] - 45s 162ms/step - loss: 0.4096 - val_loss: 0.3777\n",
      "Epoch 15/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 0.3723 - val_loss: 0.3432\n",
      "Epoch 16/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 0.3395 - val_loss: 0.3127\n",
      "Epoch 17/30\n",
      "279/279 [==============================] - 47s 169ms/step - loss: 0.3114 - val_loss: 0.2874\n",
      "Epoch 18/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 0.2861 - val_loss: 0.2632\n",
      "Epoch 19/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 0.2642 - val_loss: 0.2434\n",
      "Epoch 20/30\n",
      "279/279 [==============================] - 48s 171ms/step - loss: 0.2449 - val_loss: 0.2252\n",
      "Epoch 21/30\n",
      "279/279 [==============================] - 45s 160ms/step - loss: 0.2279 - val_loss: 0.2088\n",
      "Epoch 22/30\n",
      "279/279 [==============================] - 48s 170ms/step - loss: 0.2124 - val_loss: 0.1968\n",
      "Epoch 23/30\n",
      "279/279 [==============================] - 48s 172ms/step - loss: 0.1988 - val_loss: 0.1831\n",
      "Epoch 24/30\n",
      "279/279 [==============================] - 47s 170ms/step - loss: 0.1865 - val_loss: 0.1735\n",
      "Epoch 25/30\n",
      "279/279 [==============================] - 48s 171ms/step - loss: 0.1755 - val_loss: 0.1612\n",
      "Epoch 26/30\n",
      "279/279 [==============================] - 48s 173ms/step - loss: 0.1653 - val_loss: 0.1518\n",
      "Epoch 27/30\n",
      "279/279 [==============================] - 48s 171ms/step - loss: 0.1564 - val_loss: 0.1435\n",
      "Epoch 28/30\n",
      "279/279 [==============================] - 48s 171ms/step - loss: 0.1478 - val_loss: 0.1362\n",
      "Epoch 29/30\n",
      "279/279 [==============================] - 48s 171ms/step - loss: 0.1406 - val_loss: 0.1286\n",
      "Epoch 30/30\n",
      "279/279 [==============================] - 48s 171ms/step - loss: 0.1333 - val_loss: 0.1238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b52c39f50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = Encoder_decoder(encoder_inputs_length=20, decoder_inputs_length=20, output_vocab_size=vocab_size_eng, batch_size=1024)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\n",
    "\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "\n",
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=train_dataloader, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:35:24.590263Z",
     "iopub.status.busy": "2023-01-24T12:35:24.589436Z",
     "iopub.status.idle": "2023-01-24T12:35:24.596655Z",
     "shell.execute_reply": "2023-01-24T12:35:24.595733Z",
     "shell.execute_reply.started": "2023-01-24T12:35:24.590221Z"
    },
    "id": "GnQcAMhrpDj2",
    "outputId": "05d224da-bfd3-446c-85e2-b4f1923f27a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Encoder)          multiple                  1652818   \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  1683668   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  3387260   \n",
      "=================================================================\n",
      "Total params: 6,723,746\n",
      "Trainable params: 6,723,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:35:42.812815Z",
     "iopub.status.busy": "2023-01-24T12:35:42.812434Z",
     "iopub.status.idle": "2023-01-24T12:35:42.821401Z",
     "shell.execute_reply": "2023-01-24T12:35:42.820394Z",
     "shell.execute_reply.started": "2023-01-24T12:35:42.812782Z"
    },
    "id": "hKJP9CkHthjF"
   },
   "outputs": [],
   "source": [
    "# ref.: https://github.com/AbhijeetWaghchaure/NLP-Attention-Mechanism/blob/ \n",
    "def predict(input_sentence):\n",
    "    token = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "    pad = pad_sequences(token, maxlen=20, padding='post', truncating='post', dtype='int32')\n",
    "    embedd = model.layers[0].embedding(pad)\n",
    "    encoder_ouput, encoder_state_h, encoder_state_c = model.layers[0].lstm(embedd)\n",
    "    init_idx = tknizer_eng.word_index['<start>']\n",
    "    init_idx = np.reshape(init_idx, (1,1))\n",
    "    res = np.zeros((20,20))\n",
    "    \n",
    "    pred_sent = []\n",
    "    for i in range(20):\n",
    "        decoder_output, decoder_state_h, decoder_state_c = model.layers[1](init_idx, [encoder_state_h, encoder_state_c])\n",
    "        output = model.layers[2](decoder_output)\n",
    "        encoder_state_h = decoder_state_h\n",
    "        encoder_state_c = decoder_state_c\n",
    "        output_idx = np.argmax(output)\n",
    "        init_idxs = np.reshape(output_idx,(1,1))\n",
    "        pred_sent.append(tknizer_eng.index_word[output_idx])\n",
    "        if tknizer_eng.index_word[output_idx]=='<end>':\n",
    "            break\n",
    "    return ' '.join(pred_sent)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:36:33.656866Z",
     "iopub.status.busy": "2023-01-24T12:36:33.656495Z",
     "iopub.status.idle": "2023-01-24T12:37:01.985303Z",
     "shell.execute_reply": "2023-01-24T12:37:01.984354Z",
     "shell.execute_reply.started": "2023-01-24T12:36:33.656836Z"
    },
    "id": "WP3A7cr3_OCd",
    "outputId": "4d27ce85-a939-4a49-8f4b-27545813c0d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score: 1.60834302473003e-231\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "italian = validation['italian'].values[0:1000]\n",
    "english = validation['english_out'].values[0:1000]\n",
    "bleu_score = []\n",
    "\n",
    "for i in range(1000):    \n",
    "    pred = predict(italian[i])\n",
    "    bleu_score.append(sentence_bleu(english[i], pred))\n",
    "    \n",
    "print('Bleu Score:', np.average(bleu_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWFDxZXLOfJ"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZhX3K9GLOfJ"
   },
   "source": [
    "## Task -2: Including Attention mechanisum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3d7GeBMGbsJ"
   },
   "source": [
    "1. Use the preprocessed data from Task-1\n",
    "\n",
    "2. You have to implement an Encoder and Decoder architecture with  \n",
    "attention as discussed in the reference notebook.\n",
    "\n",
    "    * Encoder   - with 1 layer LSTM <br>\n",
    "    * Decoder   - with 1 layer LSTM<br>\n",
    "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
    "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
    " As a part of this assignment **you need to create 3 models for each scoring function**\n",
    "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
    "\n",
    "    * In model 1 you need to implemnt \"dot\" score function\n",
    "    * In model 2 you need to implemnt \"general\" score function\n",
    "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
    "    \n",
    " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
    "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
    "\n",
    "5. Using attention weights, you can plot the attention plots, \n",
    "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
    "\n",
    "6. The attention layer has to be written by yourself only. \n",
    "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
    "\n",
    "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
    "\n",
    "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
    " Check the reference notebook for better understanding.\n",
    "\n",
    "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
    "\n",
    "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
    "\n",
    "11. Resources:\n",
    "    a. Check the reference notebook\n",
    "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
    "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
    "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4KIsGxLOfK"
   },
   "source": [
    "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMm3ADQDLOfK"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:37:15.030742Z",
     "iopub.status.busy": "2023-01-24T12:37:15.030311Z",
     "iopub.status.idle": "2023-01-24T12:37:15.042579Z",
     "shell.execute_reply": "2023-01-24T12:37:15.041396Z",
     "shell.execute_reply.started": "2023-01-24T12:37:15.030707Z"
    },
    "id": "cdVfhBgmZoaf"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_dim = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_output = 0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "    \n",
    "    def call(self,input_sentances, states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        input_embedd = self.embedding(input_sentances)\n",
    "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
    "        \n",
    "        return self.lstm_output, self.lstm_state_h, self.lstm_state_c\n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ub9aN-hK244"
   },
   "source": [
    "<font color='cyan'>**Grader function - 1**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:37:18.109428Z",
     "iopub.status.busy": "2023-01-24T12:37:18.109060Z",
     "iopub.status.idle": "2023-01-24T12:37:18.148611Z",
     "shell.execute_reply": "2023-01-24T12:37:18.147614Z",
     "shell.execute_reply.started": "2023-01-24T12:37:18.109397Z"
    },
    "id": "wRoe65b9LB0D",
    "outputId": "e4e8b881-da93-4c48-aa18-03ebccd7691f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_encoder():\n",
    "    \n",
    "    '''\n",
    "        vocab-size: Unique words of the input language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        lstm_size: Number of lstm units in encoder,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    \n",
    "    vocab_size=10\n",
    "    embedding_size=20\n",
    "    lstm_size=32\n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
    "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
    "    initial_state=encoder.initialize_states(batch_size)\n",
    "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
    "    \n",
    "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
    "    return True\n",
    "print(grader_check_encoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXn278lhLYRM"
   },
   "source": [
    "<font color='blue'>**Attention**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:44:33.448496Z",
     "iopub.status.busy": "2023-01-24T12:44:33.448146Z",
     "iopub.status.idle": "2023-01-24T12:44:33.459108Z",
     "shell.execute_reply": "2023-01-24T12:44:33.458126Z",
     "shell.execute_reply.started": "2023-01-24T12:44:33.448467Z"
    },
    "id": "jFoDGWQLxE81"
   },
   "outputs": [],
   "source": [
    "# ref.: https://vineethaswani2.medium.com/spelling-error-correction-7154f781354c\n",
    "from tensorflow.keras.layers import Dot\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    '''\n",
    "      Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "    '''\n",
    "    def __init__(self,scoring_function, att_units):\n",
    "        super().__init__()\n",
    "        self.scoring_function = scoring_function\n",
    "\n",
    "        if self.scoring_function=='dot':\n",
    "            self.dot = Dot(axes = (1, 2))\n",
    "      \n",
    "        if scoring_function == 'general':\n",
    "            self.dense_1 = Dense(att_units)\n",
    "            self.dot = Dot(axes = (1, 2))\n",
    "      \n",
    "        elif scoring_function == 'concat':\n",
    "            self.dense_2 = Dense(att_units)\n",
    "            self.dense_3 = Dense(att_units)\n",
    "            self.dense_4 = Dense(1)\n",
    "    \n",
    "    \n",
    "    def call(self,decoder_hidden_state,encoder_output):\n",
    "        \n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        \n",
    "        if self.scoring_function == 'dot':\n",
    "            res = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), encoder_output]), (0, 2,1))\n",
    "\n",
    "        elif self.scoring_function == 'general':\n",
    "            mul = self.dense_1(encoder_output)\n",
    "            res = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), mul]), (0, 2,1))\n",
    "      \n",
    "        elif self.scoring_function == 'concat':\n",
    "            i = self.dense_2(decoder_hidden_state) + self.dense_3(encoder_output)\n",
    "            act = tf.nn.tanh(i)\n",
    "            res = self.dense_4(act)\n",
    "      \n",
    "        weights = tf.nn.softmax(res, axis =1)\n",
    "        con_vector = weights * encoder_output\n",
    "        con_vector = tf.reduce_sum(con_vector, axis=1)\n",
    "        \n",
    "        return con_vector, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExQDlxI9LuqK"
   },
   "source": [
    "<font color='cyan'>**Grader function - 2**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:44:36.737077Z",
     "iopub.status.busy": "2023-01-24T12:44:36.736387Z",
     "iopub.status.idle": "2023-01-24T12:44:36.773824Z",
     "shell.execute_reply": "2023-01-24T12:44:36.772740Z",
     "shell.execute_reply.started": "2023-01-24T12:44:36.737041Z"
    },
    "id": "51x50h_TLrl9",
    "outputId": "2e472142-ec90-4499-f0d8-6382062dce84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_attention(scoring_fun):\n",
    "    \n",
    "    ''' \n",
    "        att_units: Used in matrix multiplications for scoring functions,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    \n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    att_units=32\n",
    "    \n",
    "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
    "    attention=Attention(scoring_fun,att_units)\n",
    "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
    "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
    "    return True\n",
    "print(grader_check_attention('dot'))\n",
    "print(grader_check_attention('general'))\n",
    "print(grader_check_attention('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic-FNEbfL2DN"
   },
   "source": [
    "<font color='blue'>**OneStepDecoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:44:48.978769Z",
     "iopub.status.busy": "2023-01-24T12:44:48.978362Z",
     "iopub.status.idle": "2023-01-24T12:44:48.988444Z",
     "shell.execute_reply": "2023-01-24T12:44:48.987520Z",
     "shell.execute_reply.started": "2023-01-24T12:44:48.978734Z"
    },
    "id": "r8QqGj6MnO90"
   },
   "outputs": [],
   "source": [
    "class One_Step_Decoder(tf.keras.Model):\n",
    "    def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "        super().__init__()\n",
    "        self.embed_decoder = Embedding(input_dim = tar_vocab_size, output_dim = embedding_dim)\n",
    "        self.lstm = LSTM(dec_units, return_sequences = True, return_state = True)\n",
    "        self.attention = Attention(scoring_function = score_fun, att_units = att_units)\n",
    "        self.fc = Dense(tar_vocab_size)\n",
    "\n",
    "\n",
    "    def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "        embedding = self.embed_decoder(input_to_decoder)\n",
    "        con_vector, weights = self.attention(state_h, encoder_output)    \n",
    "        input = tf.concat([tf.expand_dims(con_vector, 1), embedding], axis = -1)\n",
    "        res, decoder_h, decoder_c = self.lstm(input, [state_h, state_c])\n",
    "        res = tf.reshape(res, (-1, res.shape[2]))\n",
    "        output = self.fc(res)\n",
    "        return output, decoder_h, decoder_c, weights, con_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_I8I4EIMAXq"
   },
   "source": [
    "<font color='cyan'>**Grader function - 3**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:44:52.196574Z",
     "iopub.status.busy": "2023-01-24T12:44:52.196225Z",
     "iopub.status.idle": "2023-01-24T12:44:52.278859Z",
     "shell.execute_reply": "2023-01-24T12:44:52.277750Z",
     "shell.execute_reply.started": "2023-01-24T12:44:52.196544Z"
    },
    "id": "uLEXhChnMC1k",
    "outputId": "32a48db4-6f79-4846-fbc5-946761426261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_onestepdecoder(score_fun):\n",
    "    \n",
    "    '''\n",
    "        tar_vocab_size: Unique words of the target language,\n",
    "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
    "        input_length: Length of the target sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tar_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    dec_units=16 \n",
    "    att_units=16\n",
    "    batch_size=32\n",
    "    onestepdecoder=OneStepDecoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
    "    assert(output.shape==(batch_size,tar_vocab_size))\n",
    "    assert(state_h.shape==(batch_size,dec_units))\n",
    "    assert(state_c.shape==(batch_size,dec_units))\n",
    "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
    "    assert(context_vector.shape==(batch_size,dec_units))\n",
    "    return True\n",
    "    \n",
    "print(grader_onestepdecoder('dot'))\n",
    "print(grader_onestepdecoder('general'))\n",
    "print(grader_onestepdecoder('concat'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FHrurjUMGAi"
   },
   "source": [
    "<font color='blue'>**Decoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:44:56.306458Z",
     "iopub.status.busy": "2023-01-24T12:44:56.306112Z",
     "iopub.status.idle": "2023-01-24T12:44:56.316800Z",
     "shell.execute_reply": "2023-01-24T12:44:56.315613Z",
     "shell.execute_reply.started": "2023-01-24T12:44:56.306428Z"
    },
    "id": "syrQHkPtq0bs"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "        super().__init__()\n",
    "        self.vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.onestep_decoder = One_Step_Decoder(self.vocab_size, self.embedding_dim, self.input_length, self.dec_units, self.score_fun, self.att_units)\n",
    "\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        array = tf.TensorArray(dtype = tf.float32, size= len(input_to_decoder[0]), name='tensor decoder')\n",
    "\n",
    "        #Iterate till the length of the decoder input\n",
    "        for i in range(input_to_decoder.shape[1]):\n",
    "            output, decoder_hidden_state, decoder_cell_state, _, _ = self.onestep_decoder(input_to_decoder[:,i:i+1],encoder_output, decoder_hidden_state, decoder_cell_state)\n",
    "            array = array.write(i, output)\n",
    "        \n",
    "        array = tf.transpose(array.stack(),(1,0,2))\n",
    "        \n",
    "        # Return the tensor array\n",
    "        return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxrL-P8bMJH6"
   },
   "source": [
    "<font color='cyan'>**Grader function - 4**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:45:00.599868Z",
     "iopub.status.busy": "2023-01-24T12:45:00.599496Z",
     "iopub.status.idle": "2023-01-24T12:45:00.875404Z",
     "shell.execute_reply": "2023-01-24T12:45:00.874348Z",
     "shell.execute_reply.started": "2023-01-24T12:45:00.599837Z"
    },
    "id": "rtbx6onFMJXb",
    "outputId": "2ec7beb9-9d26-4d49-8f80-f4c938fd2dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_decoder(score_fun):\n",
    "    \n",
    "    '''\n",
    "        out_vocab_size: Unique words of the target language,\n",
    "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
    "        input_length: Length of the target sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    out_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=11\n",
    "    dec_units=16 \n",
    "    att_units=16\n",
    "    batch_size=32\n",
    "    \n",
    "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    \n",
    "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
    "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
    "    return True\n",
    "print(grader_decoder('dot'))\n",
    "print(grader_decoder('general'))\n",
    "print(grader_decoder('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC1T1EOoMTqC"
   },
   "source": [
    "<font color='blue'>**Encoder Decoder model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:47:20.624668Z",
     "iopub.status.busy": "2023-01-24T12:47:20.624309Z",
     "iopub.status.idle": "2023-01-24T12:47:20.632827Z",
     "shell.execute_reply": "2023-01-24T12:47:20.631814Z",
     "shell.execute_reply.started": "2023-01-24T12:47:20.624636Z"
    },
    "id": "4jpfikYfZkaj"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, inp_length ,out_length, batch_size, att_units, score):\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.inp_length = inp_length\n",
    "        self.out_length = out_length\n",
    "        self.batch_size = batch_size\n",
    "        self.att_units = att_units\n",
    "        self.score = score\n",
    "        \n",
    "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita+1, embedding_size=50, lstm_size=256, input_length=inp_length)\n",
    "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1,embedding_dim=100, input_length=self.out_length, dec_units=256, score_fun=self.score ,att_units=self.att_units)\n",
    "        self.initial_state = self.encoder.initialize_states(self.batch_size)\n",
    "\n",
    "\n",
    "    \n",
    "    def call(self,data):\n",
    "        '''\n",
    "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "        C. Pass the decoder_outputs into Dense layer \n",
    "        \n",
    "        Return decoder_outputs\n",
    "        '''\n",
    "        input,output = data[0], data[1]\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input, [self.initial_state, self.initial_state])\n",
    "        decoder_output = self.decoder(output, [encoder_h, encoder_c])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRxB-FDMJWL"
   },
   "source": [
    "<font color='blue'>**Custom loss function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:47:22.853385Z",
     "iopub.status.busy": "2023-01-24T12:47:22.853013Z",
     "iopub.status.idle": "2023-01-24T12:47:22.859423Z",
     "shell.execute_reply": "2023-01-24T12:47:22.858347Z",
     "shell.execute_reply.started": "2023-01-24T12:47:22.853351Z"
    },
    "id": "SfZET6OSxou8"
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
    "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
    "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
    "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
    "    during preprocessing to make equal length for all the sentences.\n",
    "\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QlbWAqNNlqe"
   },
   "source": [
    "<font color='blue'>**Training**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqtZUQF2NuZE"
   },
   "source": [
    "Implement dot function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:47:25.028027Z",
     "iopub.status.busy": "2023-01-24T12:47:25.027650Z",
     "iopub.status.idle": "2023-01-24T12:47:25.040997Z",
     "shell.execute_reply": "2023-01-24T12:47:25.039838Z",
     "shell.execute_reply.started": "2023-01-24T12:47:25.027994Z"
    },
    "id": "Bnt1Xrluxz3i"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
    "        self.encoder_inps = data['italian'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tknizer_eng = tknizer_eng\n",
    "        self.tknizer_ita = tknizer_ita\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:47:25.816798Z",
     "iopub.status.busy": "2023-01-24T12:47:25.816405Z",
     "iopub.status.idle": "2023-01-24T12:47:26.156638Z",
     "shell.execute_reply": "2023-01-24T12:47:26.155539Z",
     "shell.execute_reply.started": "2023-01-24T12:47:25.816764Z"
    },
    "id": "WHejgRtSx6uB",
    "outputId": "73e7dd1a-a0e7-49df-c6f4-6b9512f77a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 20) (1024, 20) (1024, 20)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_1 = Dataset(train, tknizer_ita, tknizer_eng, 20)\n",
    "test_dataset_1  = Dataset(validation, tknizer_ita, tknizer_eng, 20)\n",
    "\n",
    "train_dataloader_1 = Dataloder(train_dataset_1, batch_size=1024)\n",
    "test_dataloader_1 = Dataloder(test_dataset_1, batch_size=1024)\n",
    "\n",
    "\n",
    "print(train_dataloader_1[0][0][0].shape, train_dataloader_1[0][0][1].shape, train_dataloader_1[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T12:47:27.510710Z",
     "iopub.status.busy": "2023-01-24T12:47:27.510333Z",
     "iopub.status.idle": "2023-01-24T12:47:27.533919Z",
     "shell.execute_reply": "2023-01-24T12:47:27.533074Z",
     "shell.execute_reply.started": "2023-01-24T12:47:27.510656Z"
    },
    "id": "OVWZraF9tzVK"
   },
   "outputs": [],
   "source": [
    "model_1 = encoder_decoder(input_len=20, output_len=20, score='dot', att_units=128, batch_size=32)\n",
    "model_1.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
    "train_steps_1 = train.shape[0]//1024\n",
    "valid_steps_1 = validation.shape[0]//1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T12:48:01.349017Z",
     "iopub.status.busy": "2023-01-24T12:48:01.348638Z",
     "iopub.status.idle": "2023-01-24T13:37:38.923886Z",
     "shell.execute_reply": "2023-01-24T13:37:38.922673Z",
     "shell.execute_reply.started": "2023-01-24T12:48:01.348987Z"
    },
    "id": "9BqHntxXomk2",
    "outputId": "1fe42c45-b96c-4ea2-fd37-058e344d9a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 12:48:06.565732: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: Invalid argument: Input 1 of node encoder_decoder_2/decoder_5/while/body/_1/encoder_decoder_2/decoder_5/while/TensorListPushBack_10 was passed float from encoder_decoder_2/decoder_5/while/body/_1/encoder_decoder_2/decoder_5/while/one_step_decoder_6/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n",
      "2023-01-24 12:48:06.717608: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] layout failed: Out of range: src_output = 30, but num_outputs is only 30\n",
      "2023-01-24 12:48:06.825360: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: Invalid argument: Input 1 of node encoder_decoder_2/decoder_5/while/body/_1/encoder_decoder_2/decoder_5/while/TensorListPushBack_10 was passed float from encoder_decoder_2/decoder_5/while/body/_1/encoder_decoder_2/decoder_5/while/one_step_decoder_6/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n",
      "2023-01-24 12:48:06.934441: W tensorflow/core/common_runtime/process_function_library_runtime.cc:841] Ignoring multi-device function optimization failure: Invalid argument: Input 1 of node encoder_decoder_2/decoder_5/while/body/_1/encoder_decoder_2/decoder_5/while/TensorListPushBack_10 was passed float from encoder_decoder_2/decoder_5/while/body/_1/encoder_decoder_2/decoder_5/while/one_step_decoder_6/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 124s 423ms/step - loss: 2.3147 - val_loss: 2.3128\n",
      "Epoch 2/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 2.0138 - val_loss: 2.2194\n",
      "Epoch 3/25\n",
      "279/279 [==============================] - 118s 424ms/step - loss: 1.9776 - val_loss: 2.1297\n",
      "Epoch 4/25\n",
      "279/279 [==============================] - 119s 426ms/step - loss: 1.9731 - val_loss: 2.1206\n",
      "Epoch 5/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 1.9015 - val_loss: 2.1110\n",
      "Epoch 6/25\n",
      "279/279 [==============================] - 119s 425ms/step - loss: 1.8728 - val_loss: 2.3261\n",
      "Epoch 7/25\n",
      "279/279 [==============================] - 118s 423ms/step - loss: 1.9492 - val_loss: 2.1334\n",
      "Epoch 8/25\n",
      "279/279 [==============================] - 118s 424ms/step - loss: 1.8454 - val_loss: 2.1042\n",
      "Epoch 9/25\n",
      "279/279 [==============================] - 117s 419ms/step - loss: 1.8755 - val_loss: 2.1359\n",
      "Epoch 10/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 1.9024 - val_loss: 2.0911\n",
      "Epoch 11/25\n",
      "279/279 [==============================] - 118s 423ms/step - loss: 1.8805 - val_loss: 2.0918\n",
      "Epoch 12/25\n",
      "279/279 [==============================] - 117s 420ms/step - loss: 1.8088 - val_loss: 2.0823\n",
      "Epoch 13/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 1.7967 - val_loss: 2.1217\n",
      "Epoch 14/25\n",
      "279/279 [==============================] - 118s 423ms/step - loss: 1.8327 - val_loss: 2.1240\n",
      "Epoch 15/25\n",
      "279/279 [==============================] - 117s 421ms/step - loss: 1.8214 - val_loss: 2.1417\n",
      "Epoch 16/25\n",
      "279/279 [==============================] - 119s 425ms/step - loss: 1.8689 - val_loss: 2.1372\n",
      "Epoch 17/25\n",
      "279/279 [==============================] - 117s 420ms/step - loss: 1.8453 - val_loss: 2.1598\n",
      "Epoch 18/25\n",
      "279/279 [==============================] - 116s 416ms/step - loss: 1.7820 - val_loss: 2.1691\n",
      "Epoch 19/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 1.7997 - val_loss: 2.1364\n",
      "Epoch 20/25\n",
      "279/279 [==============================] - 118s 424ms/step - loss: 1.8423 - val_loss: 2.1552\n",
      "Epoch 21/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 1.7534 - val_loss: 2.1294\n",
      "Epoch 22/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 1.7864 - val_loss: 2.1721\n",
      "Epoch 23/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 1.8649 - val_loss: 2.1371\n",
      "Epoch 24/25\n",
      "279/279 [==============================] - 118s 422ms/step - loss: 1.7809 - val_loss: 2.1308\n",
      "Epoch 25/25\n",
      "279/279 [==============================] - 117s 420ms/step - loss: 1.7648 - val_loss: 2.1321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4abb27af10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_dataloader_1, steps_per_epoch=train_steps_1, epochs=25, validation_data=train_dataloader_1, validation_steps=valid_steps_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T13:39:25.467784Z",
     "iopub.status.busy": "2023-01-24T13:39:25.467369Z",
     "iopub.status.idle": "2023-01-24T13:39:25.474831Z",
     "shell.execute_reply": "2023-01-24T13:39:25.473735Z",
     "shell.execute_reply.started": "2023-01-24T13:39:25.467749Z"
    },
    "id": "oLxgpthTyDiU",
    "outputId": "165e98cc-330a-43f2-d76e-41c4cfd39d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_4 (Encoder)          multiple                  1652818   \n",
      "_________________________________________________________________\n",
      "decoder_5 (Decoder)          multiple                  5333329   \n",
      "=================================================================\n",
      "Total params: 6,986,147\n",
      "Trainable params: 6,986,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DpC9zlzMcXp"
   },
   "source": [
    "## <font color='blue'>**Inference**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5NhESYyMW_t"
   },
   "source": [
    "<font color='blue'>**Plot attention weights**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T13:39:52.072177Z",
     "iopub.status.busy": "2023-01-24T13:39:52.071568Z",
     "iopub.status.idle": "2023-01-24T13:39:52.079183Z",
     "shell.execute_reply": "2023-01-24T13:39:52.078241Z",
     "shell.execute_reply.started": "2023-01-24T13:39:52.072140Z"
    },
    "id": "2ACiW1nryJB0"
   },
   "outputs": [],
   "source": [
    "#Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
    "import matplotlib.ticker as ticker\n",
    "def plot_attention(attention,act,pred):\n",
    "  \n",
    "  pred,_=predict(act,plot_t2='dot')\n",
    "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
    "  fig,ax = plt.subplots(figsize=(8,6))\n",
    "  ax.matshow(attention,cmap='Blues')\n",
    "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
    "  ax.set_yticklabels([''] + pred.split(' '))\n",
    "  plt.show() \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1IhdBrgQYJr"
   },
   "source": [
    "<font color='blue'>**Predict the sentence translation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T13:41:44.088068Z",
     "iopub.status.busy": "2023-01-24T13:41:44.087710Z",
     "iopub.status.idle": "2023-01-24T13:41:44.097546Z",
     "shell.execute_reply": "2023-01-24T13:41:44.096395Z",
     "shell.execute_reply.started": "2023-01-24T13:41:44.088037Z"
    },
    "id": "mR3rkRujyQoQ"
   },
   "outputs": [],
   "source": [
    "# ref.: https://github.com/AbhijeetWaghchaure/NLP-Attention-Mechanism/blob/ \n",
    "def predict(input_sentence,plot_1):\n",
    "\n",
    "    token = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "    pad = pad_sequences(token,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
    "    encoder_1 = model_1.layers[0].initialize_states(pad.shape[0])\n",
    "    encoder_ouput_1, encoder_state_h1, encoder_state_c1 = model_1.layers[0](pad, encoder_1)\n",
    "    init_idx = tknizer_eng.word_index['<start>']\n",
    "    init_idx = tf.expand_dims([in_indexs],0)\n",
    "    att = np.zeros((20,20))\n",
    "    \n",
    "    pred_sent = []\n",
    "    for i in range(pad.shape[1]):\n",
    "    decoder_output, decoder_state_h1, decoder_state_c1, w, cv = model_1.layers[1].onestep_decoder(init_idx, encoder_ouput_1,encoder_state_h1,encoder_state_c1)\n",
    "    output_1 = model_1.layers[1](init_idx, encoder_ouput_1, encoder_state_h1, encoder_state_c1)\n",
    "    output_idx = np.argmax(output_1)\n",
    "    wt = tf.reshape(w,(-1, ))\n",
    "    att[j] = wt.numpy()\n",
    "    init_idxs = np.reshape(output_idx,(1,1))\n",
    "    pred_sent.append(tknizer_eng.index_word[output_idx])\n",
    "    \n",
    "    if tknizer_eng.index_word[output_idx]=='<end>':\n",
    "        break\n",
    "    return ' '.join(pred_sent), att\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usOCV-6Pkk5X"
   },
   "source": [
    "**ATTETNTION PLOTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T13:41:46.125640Z",
     "iopub.status.busy": "2023-01-24T13:41:46.125285Z",
     "iopub.status.idle": "2023-01-24T13:41:46.431360Z",
     "shell.execute_reply": "2023-01-24T13:41:46.430172Z",
     "shell.execute_reply.started": "2023-01-24T13:41:46.125610Z"
    },
    "id": "pQeh7GV2j6W_",
    "outputId": "a3a080c4-0cd6-4107-dc7f-4a50317ae48b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred,attention=predict('1 2 3 4','dot')\n",
    "plot_attention(attention,'1 2 3 4',pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmxIVOOQPWMu"
   },
   "source": [
    "<font color='blue'>**Calculate BLEU score**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T13:44:56.062591Z",
     "iopub.status.busy": "2023-01-24T13:44:56.061563Z",
     "iopub.status.idle": "2023-01-24T13:47:20.988834Z",
     "shell.execute_reply": "2023-01-24T13:47:20.987854Z",
     "shell.execute_reply.started": "2023-01-24T13:44:56.062521Z"
    },
    "id": "iZr7et_Eycbt",
    "outputId": "607a3d48-1726-441c-cb0d-7d5bc34e9711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score:  1.351865196330822e-231\n"
     ]
    }
   ],
   "source": [
    "italian = validation['italian'].values[:1000]\n",
    "english = validation['english_out'].values[:1000]\n",
    "bleu_score = []\n",
    "\n",
    "for i in range(1000):\n",
    "    pred,att = predict(italian[i],'dot')\n",
    "    bleu_score.append(sentence_bleu(english[i],pred))\n",
    "\n",
    "print('Bleu Score: ', np.average(bleu_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWg2ferDQvT3"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T13:48:05.704258Z",
     "iopub.status.busy": "2023-01-24T13:48:05.703561Z",
     "iopub.status.idle": "2023-01-24T14:41:06.539742Z",
     "shell.execute_reply": "2023-01-24T14:41:06.538823Z",
     "shell.execute_reply.started": "2023-01-24T13:48:05.704222Z"
    },
    "id": "AKqBjrlOLNRn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 13:48:10.819064: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: Invalid argument: Input 1 of node encoder_decoder_4/decoder_7/while/body/_1/encoder_decoder_4/decoder_7/while/TensorListPushBack_10 was passed float from encoder_decoder_4/decoder_7/while/body/_1/encoder_decoder_4/decoder_7/while/one_step_decoder_8/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n",
      "2023-01-24 13:48:10.942013: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] layout failed: Out of range: src_output = 30, but num_outputs is only 30\n",
      "2023-01-24 13:48:11.058775: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: Invalid argument: Input 1 of node encoder_decoder_4/decoder_7/while/body/_1/encoder_decoder_4/decoder_7/while/TensorListPushBack_10 was passed float from encoder_decoder_4/decoder_7/while/body/_1/encoder_decoder_4/decoder_7/while/one_step_decoder_8/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n",
      "2023-01-24 13:48:11.180502: W tensorflow/core/common_runtime/process_function_library_runtime.cc:841] Ignoring multi-device function optimization failure: Invalid argument: Input 1 of node encoder_decoder_4/decoder_7/while/body/_1/encoder_decoder_4/decoder_7/while/TensorListPushBack_10 was passed float from encoder_decoder_4/decoder_7/while/body/_1/encoder_decoder_4/decoder_7/while/one_step_decoder_8/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 133s 457ms/step - loss: 2.2350 - val_loss: 2.0873\n",
      "Epoch 2/25\n",
      "279/279 [==============================] - 125s 448ms/step - loss: 1.9612 - val_loss: 2.0698\n",
      "Epoch 3/25\n",
      "279/279 [==============================] - 125s 448ms/step - loss: 1.9098 - val_loss: 2.0615\n",
      "Epoch 4/25\n",
      "279/279 [==============================] - 126s 452ms/step - loss: 1.9059 - val_loss: 2.1039\n",
      "Epoch 5/25\n",
      "279/279 [==============================] - 125s 448ms/step - loss: 1.9278 - val_loss: 2.1178\n",
      "Epoch 6/25\n",
      "279/279 [==============================] - 126s 451ms/step - loss: 2.0238 - val_loss: 2.1755\n",
      "Epoch 7/25\n",
      "279/279 [==============================] - 126s 452ms/step - loss: 1.8825 - val_loss: 2.1850\n",
      "Epoch 8/25\n",
      "279/279 [==============================] - 125s 447ms/step - loss: 1.9009 - val_loss: 2.1208\n",
      "Epoch 9/25\n",
      "279/279 [==============================] - 126s 450ms/step - loss: 2.0083 - val_loss: 2.1451\n",
      "Epoch 10/25\n",
      "279/279 [==============================] - 127s 454ms/step - loss: 1.8548 - val_loss: 2.3574\n",
      "Epoch 11/25\n",
      "279/279 [==============================] - 127s 455ms/step - loss: 2.1019 - val_loss: 2.2619\n",
      "Epoch 12/25\n",
      "279/279 [==============================] - 126s 453ms/step - loss: 1.9517 - val_loss: 2.1010\n",
      "Epoch 13/25\n",
      "279/279 [==============================] - 127s 454ms/step - loss: 1.8293 - val_loss: 2.0694\n",
      "Epoch 14/25\n",
      "279/279 [==============================] - 127s 455ms/step - loss: 1.8394 - val_loss: 2.1194\n",
      "Epoch 15/25\n",
      "279/279 [==============================] - 128s 458ms/step - loss: 1.8068 - val_loss: 2.0963\n",
      "Epoch 16/25\n",
      "279/279 [==============================] - 127s 455ms/step - loss: 1.8258 - val_loss: 2.1141\n",
      "Epoch 17/25\n",
      "279/279 [==============================] - 126s 452ms/step - loss: 1.8448 - val_loss: 2.0861\n",
      "Epoch 18/25\n",
      "279/279 [==============================] - 126s 452ms/step - loss: 1.8016 - val_loss: 2.0670\n",
      "Epoch 19/25\n",
      "279/279 [==============================] - 126s 452ms/step - loss: 1.7685 - val_loss: 2.0877\n",
      "Epoch 20/25\n",
      "279/279 [==============================] - 127s 455ms/step - loss: 1.7833 - val_loss: 2.0838\n",
      "Epoch 21/25\n",
      "279/279 [==============================] - 127s 454ms/step - loss: 1.8221 - val_loss: 2.0869\n",
      "Epoch 22/25\n",
      "279/279 [==============================] - 127s 454ms/step - loss: 1.7748 - val_loss: 2.0761\n",
      "Epoch 23/25\n",
      "279/279 [==============================] - 126s 452ms/step - loss: 1.7289 - val_loss: 2.0959\n",
      "Epoch 24/25\n",
      "279/279 [==============================] - 127s 454ms/step - loss: 1.7795 - val_loss: 2.1230\n",
      "Epoch 25/25\n",
      "279/279 [==============================] - 125s 447ms/step - loss: 1.7799 - val_loss: 2.1063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46adfccc90>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = encoder_decoder(input_len=20, output_len=20, score='general', att_units=256, batch_size=32)\n",
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
    "train_steps_2 = train.shape[0]//1024\n",
    "valid_steps_2 = validation.shape[0]//1024\n",
    "\n",
    "model_2.fit(train_dataloader_2, steps_per_epoch=train_steps_2, epochs=25, validation_data=train_dataloader_2, validation_steps=valid_steps_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T14:41:10.308791Z",
     "iopub.status.busy": "2023-01-24T14:41:10.308400Z",
     "iopub.status.idle": "2023-01-24T14:41:10.318596Z",
     "shell.execute_reply": "2023-01-24T14:41:10.314640Z",
     "shell.execute_reply.started": "2023-01-24T14:41:10.308756Z"
    },
    "id": "Jgo0iw8uy1UJ",
    "outputId": "8ccbfd0e-93e9-483b-8643-519d5fa0f5db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_6 (Encoder)          multiple                  1652818   \n",
      "_________________________________________________________________\n",
      "decoder_7 (Decoder)          multiple                  5399121   \n",
      "=================================================================\n",
      "Total params: 7,051,939\n",
      "Trainable params: 7,051,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T14:41:12.190056Z",
     "iopub.status.busy": "2023-01-24T14:41:12.189727Z",
     "iopub.status.idle": "2023-01-24T14:41:12.196634Z",
     "shell.execute_reply": "2023-01-24T14:41:12.195705Z",
     "shell.execute_reply.started": "2023-01-24T14:41:12.190028Z"
    },
    "id": "2GqDAETzy0x2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "def plot_attention(attention,act,pred):\n",
    "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
    "\n",
    "  pred,_=predict(act,plot_t2='general')\n",
    "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
    "  fig,ax = plt.subplots(figsize=(8,6))\n",
    "  ax.matshow(attention,cmap='Blues')\n",
    "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
    "  ax.set_yticklabels([''] + pred.split(' '))\n",
    "  plt.show() \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T14:41:13.728795Z",
     "iopub.status.busy": "2023-01-24T14:41:13.728409Z",
     "iopub.status.idle": "2023-01-24T14:41:14.083323Z",
     "shell.execute_reply": "2023-01-24T14:41:14.079689Z",
     "shell.execute_reply.started": "2023-01-24T14:41:13.728761Z"
    },
    "id": "-GW2mb4cYneK",
    "outputId": "c1651131-6d8c-4f60-8182-e10e872ac58c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred,attention=predict('1 2 3 4','general')\n",
    "plot_attention(attention,'1 2 3 4',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T14:41:15.664511Z",
     "iopub.status.busy": "2023-01-24T14:41:15.664157Z",
     "iopub.status.idle": "2023-01-24T14:41:15.673721Z",
     "shell.execute_reply": "2023-01-24T14:41:15.672247Z",
     "shell.execute_reply.started": "2023-01-24T14:41:15.664481Z"
    },
    "id": "7PxiQuDby41L"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence,plot_1):\n",
    "\n",
    "    token = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "    pad = pad_sequences(token,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
    "    encoder_1 = model_1.layers[0].initialize_states(pad.shape[0])\n",
    "    encoder_ouput_1, encoder_state_h1, encoder_state_c1 = model_1.layers[0](pad, encoder_1)\n",
    "    init_idx = tknizer_eng.word_index['<start>']\n",
    "    init_idx = tf.expand_dims([in_indexs],0)\n",
    "    att = np.zeros((20,20))\n",
    "    \n",
    "    pred_sent = []\n",
    "    for i in range(pad.shape[1]):\n",
    "    decoder_output, decoder_state_h1, decoder_state_c1, w, cv = model_1.layers[1].onestep_decoder(init_idx, encoder_ouput_1,encoder_state_h1,encoder_state_c1)\n",
    "    output_1 = model_1.layers[1](init_idx, encoder_ouput_1, encoder_state_h1, encoder_state_c1)\n",
    "    output_idx = np.argmax(output_1)\n",
    "    wt = tf.reshape(w,(-1, ))\n",
    "    att[j] = wt.numpy()\n",
    "    init_idxs = np.reshape(output_idx,(1,1))\n",
    "    pred_sent.append(tknizer_eng.index_word[output_idx])\n",
    "    \n",
    "    if tknizer_eng.index_word[output_idx]=='<end>':\n",
    "        break\n",
    "    return ' '.join(pred_sent), att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T14:43:04.196545Z",
     "iopub.status.busy": "2023-01-24T14:43:04.196177Z",
     "iopub.status.idle": "2023-01-24T14:44:25.273976Z",
     "shell.execute_reply": "2023-01-24T14:44:25.272943Z",
     "shell.execute_reply.started": "2023-01-24T14:43:04.196513Z"
    },
    "id": "NJIATpUjkPji",
    "outputId": "abbf360c-3512-4aae-c928-eb4e339d79a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score:  1.590842458919906e-231\n"
     ]
    }
   ],
   "source": [
    "italian = validation['italian'].values[:1000]\n",
    "english = validation['english_out'].values[:1000]\n",
    "bleu_score = []\n",
    "\n",
    "for i in range(1000):\n",
    "    pred,att = predict(italian[i],'general')\n",
    "    bleu_score.append(sentence_bleu(english[i],pred))\n",
    "\n",
    "print('Bleu Score: ', np.average(bleu_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB1jRUqZQ9AM"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T14:44:55.094484Z",
     "iopub.status.busy": "2023-01-24T14:44:55.094129Z",
     "iopub.status.idle": "2023-01-24T14:44:55.120172Z",
     "shell.execute_reply": "2023-01-24T14:44:55.119302Z",
     "shell.execute_reply.started": "2023-01-24T14:44:55.094453Z"
    },
    "id": "P6C2dI4lZSB4"
   },
   "outputs": [],
   "source": [
    "model_3 = encoder_decoder(input_len=20, output_len=20, score='concat', att_units=256, batch_size=32)\n",
    "model_3.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
    "train_steps_3 = train.shape[0]//1024\n",
    "valid_steps_3 = validation.shape[0]//1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T14:44:56.374128Z",
     "iopub.status.busy": "2023-01-24T14:44:56.373510Z",
     "iopub.status.idle": "2023-01-24T15:40:16.135617Z",
     "shell.execute_reply": "2023-01-24T15:40:16.134610Z",
     "shell.execute_reply.started": "2023-01-24T14:44:56.374095Z"
    },
    "id": "I7G4n0NUZVrL",
    "outputId": "5e0c3e9c-a1c5-4c65-9712-a4c7dd623f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 14:45:01.170146: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: Invalid argument: Input 1 of node encoder_decoder_5/decoder_8/while/body/_1/encoder_decoder_5/decoder_8/while/TensorListPushBack_10 was passed float from encoder_decoder_5/decoder_8/while/body/_1/encoder_decoder_5/decoder_8/while/one_step_decoder_9/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n",
      "2023-01-24 14:45:01.302782: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] layout failed: Out of range: src_output = 30, but num_outputs is only 30\n",
      "2023-01-24 14:45:01.427288: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: Invalid argument: Input 1 of node encoder_decoder_5/decoder_8/while/body/_1/encoder_decoder_5/decoder_8/while/TensorListPushBack_10 was passed float from encoder_decoder_5/decoder_8/while/body/_1/encoder_decoder_5/decoder_8/while/one_step_decoder_9/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n",
      "2023-01-24 14:45:01.564981: W tensorflow/core/common_runtime/process_function_library_runtime.cc:841] Ignoring multi-device function optimization failure: Invalid argument: Input 1 of node encoder_decoder_5/decoder_8/while/body/_1/encoder_decoder_5/decoder_8/while/TensorListPushBack_10 was passed float from encoder_decoder_5/decoder_8/while/body/_1/encoder_decoder_5/decoder_8/while/one_step_decoder_9/osd_LSTM/PartitionedCall:7 incompatible with expected variant.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 139s 477ms/step - loss: 8.5265 - val_loss: 8.4068\n",
      "Epoch 2/25\n",
      "279/279 [==============================] - 132s 474ms/step - loss: 8.3051 - val_loss: 8.3689\n",
      "Epoch 3/25\n",
      "279/279 [==============================] - 132s 472ms/step - loss: 8.2730 - val_loss: 8.3676\n",
      "Epoch 4/25\n",
      "279/279 [==============================] - 132s 474ms/step - loss: 8.2516 - val_loss: 8.4113\n",
      "Epoch 5/25\n",
      "279/279 [==============================] - 130s 466ms/step - loss: 8.3320 - val_loss: 8.4037\n",
      "Epoch 6/25\n",
      "279/279 [==============================] - 132s 473ms/step - loss: 8.3001 - val_loss: 8.3632\n",
      "Epoch 7/25\n",
      "279/279 [==============================] - 132s 472ms/step - loss: 8.2687 - val_loss: 8.3257\n",
      "Epoch 8/25\n",
      "279/279 [==============================] - 131s 470ms/step - loss: 8.2337 - val_loss: 8.3284\n",
      "Epoch 9/25\n",
      "279/279 [==============================] - 132s 472ms/step - loss: 8.2621 - val_loss: 8.3592\n",
      "Epoch 10/25\n",
      "279/279 [==============================] - 131s 470ms/step - loss: 8.2110 - val_loss: 8.3311\n",
      "Epoch 11/25\n",
      "279/279 [==============================] - 132s 474ms/step - loss: 8.1897 - val_loss: 8.3417\n",
      "Epoch 12/25\n",
      "279/279 [==============================] - 133s 477ms/step - loss: 8.1490 - val_loss: 8.3977\n",
      "Epoch 13/25\n",
      "279/279 [==============================] - 131s 470ms/step - loss: 8.1657 - val_loss: 8.4171\n",
      "Epoch 14/25\n",
      "279/279 [==============================] - 132s 473ms/step - loss: 8.2849 - val_loss: 8.4019\n",
      "Epoch 15/25\n",
      "279/279 [==============================] - 132s 472ms/step - loss: 8.2480 - val_loss: 8.3450\n",
      "Epoch 16/25\n",
      "279/279 [==============================] - 131s 469ms/step - loss: 8.1787 - val_loss: 8.3456\n",
      "Epoch 17/25\n",
      "279/279 [==============================] - 130s 467ms/step - loss: 8.1766 - val_loss: 8.3840\n",
      "Epoch 18/25\n",
      "279/279 [==============================] - 132s 473ms/step - loss: 8.1398 - val_loss: 8.3352\n",
      "Epoch 19/25\n",
      "279/279 [==============================] - 132s 473ms/step - loss: 8.0900 - val_loss: 8.3258\n",
      "Epoch 20/25\n",
      "279/279 [==============================] - 132s 471ms/step - loss: 8.0807 - val_loss: 8.3420\n",
      "Epoch 21/25\n",
      "279/279 [==============================] - 132s 472ms/step - loss: 8.1308 - val_loss: 8.3571\n",
      "Epoch 22/25\n",
      "279/279 [==============================] - 130s 466ms/step - loss: 8.1306 - val_loss: 8.3349\n",
      "Epoch 23/25\n",
      "279/279 [==============================] - 131s 471ms/step - loss: 8.2144 - val_loss: 8.3291\n",
      "Epoch 24/25\n",
      "279/279 [==============================] - 131s 470ms/step - loss: 8.2101 - val_loss: 8.3552\n",
      "Epoch 25/25\n",
      "279/279 [==============================] - 132s 471ms/step - loss: 8.1360 - val_loss: 8.4136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46abd14d90>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train_dataloader_3, steps_per_epoch=train_steps_3, epochs=25, validation_data=train_dataloader_3, validation_steps=valid_steps_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T15:40:16.138041Z",
     "iopub.status.busy": "2023-01-24T15:40:16.137663Z",
     "iopub.status.idle": "2023-01-24T15:40:16.144862Z",
     "shell.execute_reply": "2023-01-24T15:40:16.143818Z",
     "shell.execute_reply.started": "2023-01-24T15:40:16.138005Z"
    },
    "id": "MRbRL2K8zGxM",
    "outputId": "3eeb0bc4-3132-4f45-9989-59451c0ffb0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_7 (Encoder)          multiple                  1652818   \n",
      "_________________________________________________________________\n",
      "decoder_8 (Decoder)          multiple                  5465170   \n",
      "=================================================================\n",
      "Total params: 7,117,988\n",
      "Trainable params: 7,117,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T15:40:16.147050Z",
     "iopub.status.busy": "2023-01-24T15:40:16.146363Z",
     "iopub.status.idle": "2023-01-24T15:40:16.158015Z",
     "shell.execute_reply": "2023-01-24T15:40:16.157114Z",
     "shell.execute_reply.started": "2023-01-24T15:40:16.147015Z"
    },
    "id": "5LRVqM68Z9Fz"
   },
   "outputs": [],
   "source": [
    "# ref.: https://github.com/AbhijeetWaghchaure/NLP-Attention-Mechanism/blob/ \n",
    "def predict(input_sentence,plot_1):\n",
    "\n",
    "    token = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "    pad = pad_sequences(token,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
    "    encoder_1 = model_1.layers[0].initialize_states(pad.shape[0])\n",
    "    encoder_ouput_1, encoder_state_h1, encoder_state_c1 = model_1.layers[0](pad, encoder_1)\n",
    "    init_idx = tknizer_eng.word_index['<start>']\n",
    "    init_idx = tf.expand_dims([in_indexs],0)\n",
    "    att = np.zeros((20,20))\n",
    "    \n",
    "    pred_sent = []\n",
    "    for i in range(pad.shape[1]):\n",
    "    decoder_output, decoder_state_h1, decoder_state_c1, w, cv = model_1.layers[1].onestep_decoder(init_idx, encoder_ouput_1,encoder_state_h1,encoder_state_c1)\n",
    "    output_1 = model_1.layers[1](init_idx, encoder_ouput_1, encoder_state_h1, encoder_state_c1)\n",
    "    output_idx = np.argmax(output_1)\n",
    "    wt = tf.reshape(w,(-1, ))\n",
    "    att[j] = wt.numpy()\n",
    "    init_idxs = np.reshape(output_idx,(1,1))\n",
    "    pred_sent.append(tknizer_eng.index_word[output_idx])\n",
    "    \n",
    "    if tknizer_eng.index_word[output_idx]=='<end>':\n",
    "        break\n",
    "    return ' '.join(pred_sent), att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T15:40:16.161076Z",
     "iopub.status.busy": "2023-01-24T15:40:16.160579Z",
     "iopub.status.idle": "2023-01-24T15:40:16.168791Z",
     "shell.execute_reply": "2023-01-24T15:40:16.167738Z",
     "shell.execute_reply.started": "2023-01-24T15:40:16.161042Z"
    },
    "id": "P8-4XDE5zKrh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "def plot_attention(attention,act,pred):\n",
    "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
    "\n",
    "  pred,_=predict(act,plot_t2='concat')\n",
    "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
    "  fig,ax = plt.subplots(figsize=(8,6))\n",
    "  ax.matshow(attention,cmap='Blues')\n",
    "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
    "  ax.set_yticklabels([''] + pred.split(' '))\n",
    "  plt.show() \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T15:40:16.171312Z",
     "iopub.status.busy": "2023-01-24T15:40:16.170851Z",
     "iopub.status.idle": "2023-01-24T15:40:17.164659Z",
     "shell.execute_reply": "2023-01-24T15:40:17.163508Z",
     "shell.execute_reply.started": "2023-01-24T15:40:16.171217Z"
    },
    "id": "LLQlEDEGaI_j",
    "outputId": "21c843a9-f7a5-49b8-e3b2-c68f1a6cf61d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred,attention=predict('1 2 3 4','concat')\n",
    "plot_attention(attention,'1 2 3 4',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-24T15:40:17.166668Z",
     "iopub.status.busy": "2023-01-24T15:40:17.166047Z",
     "iopub.status.idle": "2023-01-24T15:44:47.800434Z",
     "shell.execute_reply": "2023-01-24T15:44:47.798844Z",
     "shell.execute_reply.started": "2023-01-24T15:40:17.166631Z"
    },
    "id": "sbmmEMtazNyT",
    "outputId": "5da81fa6-32ca-4580-d0c2-726e8030ae78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu Score:  1.1453589005092468e-231\n"
     ]
    }
   ],
   "source": [
    "italian = validation['italian'].values[:1000]\n",
    "english = validation['english_out'].values[:1000]\n",
    "bleu_score = []\n",
    "\n",
    "for i in range(1000):\n",
    "    pred,att = predict(italian[i],'concat')\n",
    "    bleu_score.append(sentence_bleu(english[i],pred))\n",
    "\n",
    "print('Bleu Score: ', np.average(bleu_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLo30Q7Istma"
   },
   "source": [
    "**OBSERVATIONS OF ATTENTION MECHANISM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T17:26:26.204191Z",
     "iopub.status.busy": "2023-01-24T17:26:26.203798Z",
     "iopub.status.idle": "2023-01-24T17:26:26.211642Z",
     "shell.execute_reply": "2023-01-24T17:26:26.210657Z",
     "shell.execute_reply.started": "2023-01-24T17:26:26.204158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------+\n",
      "| Sr. No. | Scoring Function | Bleu Score |\n",
      "+---------+------------------+------------+\n",
      "|    1    |       DOT        |   1.3518   |\n",
      "|    2    |     GENERAL      |   1.5908   |\n",
      "|    3    |      CONCAT      |   1.1453   |\n",
      "+---------+------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "  \n",
    "# Specify the Column Names while initializing the Table\n",
    "Table = PrettyTable([\"Sr. No.\", \"Scoring Function\", \"Bleu Score\"])\n",
    "  \n",
    "# Add rows\n",
    "Table.add_row([\"1\", \"DOT\", \"1.3518\"])\n",
    "Table.add_row([\"2\", \"GENERAL\", \"1.5908\"])\n",
    "Table.add_row([\"3\", \"CONCAT\", \"1.1453\"])\n",
    "                     \n",
    "print(Table)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
