{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwoTWIysaNmc"
   },
   "source": [
    "# <font color='red'> Spoken Digit Recognition</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPO3mjDDaNmf"
   },
   "source": [
    "\n",
    "In this notebook, You will do Spoken Digit Recognition. \n",
    "\n",
    "Input - speech signal, output - digit number\n",
    "\n",
    "\n",
    "\n",
    "It contains  \n",
    "\n",
    "1. Reading the dataset. and Preprocess the data set. Detailed instrctions are given below. You have to write the code in the same cell which contains the instrction. \n",
    "2. Training the LSTM with RAW data\n",
    "3. Converting to spectrogram and Training the LSTM network\n",
    "4. Creating the augmented data and doing step 2 and 3 again.  \n",
    "\n",
    "<font size=5>Instructions:</font>\n",
    "\n",
    "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. If you manipulate any, it will be considered as plagiarised. \n",
    "    \n",
    "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
    "    \n",
    "    3. Please return outputs in the same format what we asked. Eg. Don't return List of we are asking for a numpy array.\n",
    "    \n",
    "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
    "    \n",
    "    5. We are giving instructions at each section if necessary, please follow them. \n",
    "\n",
    "<font size=5>Every Grader function has to return True. </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:55.301307Z",
     "iopub.status.busy": "2023-01-26T10:26:55.300248Z",
     "iopub.status.idle": "2023-01-26T10:26:56.078999Z",
     "shell.execute_reply": "2023-01-26T10:26:56.077874Z",
     "shell.execute_reply.started": "2023-01-26T10:26:55.301216Z"
    },
    "id": "_qGuPcj-aNmh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "##if you need any imports you can do that here. \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdhFzGK1aNmo"
   },
   "source": [
    "We shared recordings.zip, please unzip those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.086373Z",
     "iopub.status.busy": "2023-01-26T10:26:56.085457Z",
     "iopub.status.idle": "2023-01-26T10:26:56.104972Z",
     "shell.execute_reply": "2023-01-26T10:26:56.103968Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.086331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import OS module\n",
    "import os\n",
    "\n",
    "all_files = []\n",
    "path = \"/kaggle/input/spoken-digit-rec/recordings\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for files in dir_list:\n",
    "    res = os.path.join(path, files)\n",
    "    all_files.append(res)\n",
    "    \n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NYYpfqoaNmv"
   },
   "source": [
    "<font size=4>Grader function 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.106976Z",
     "iopub.status.busy": "2023-01-26T10:26:56.106391Z",
     "iopub.status.idle": "2023-01-26T10:26:56.114547Z",
     "shell.execute_reply": "2023-01-26T10:26:56.113548Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.106938Z"
    },
    "id": "2oJSOmYBaNmx",
    "outputId": "d4509e7d-1cb6-4e7f-e469-ef40314a8510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_files():\n",
    "    temp = len(all_files)==2000\n",
    "    temp1 = all([x[-3:]==\"wav\" for x in all_files])\n",
    "    temp = temp and temp1\n",
    "    return temp\n",
    "grader_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhvSIN6raNm3"
   },
   "source": [
    "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "You can get the label from the first letter of name.  \n",
    "Eg: 0_jackson_0 --> 0  \n",
    "0_jackson_43 --> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZbhCvvRPPMw"
   },
   "source": [
    "## Exploring the sound dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.118737Z",
     "iopub.status.busy": "2023-01-26T10:26:56.117745Z",
     "iopub.status.idle": "2023-01-26T10:26:56.125189Z",
     "shell.execute_reply": "2023-01-26T10:26:56.124209Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.118702Z"
    },
    "id": "ilJsqdhhPMed"
   },
   "outputs": [],
   "source": [
    "#It is a good programming practise to explore the dataset that you are dealing with. This dataset is unique in itself because it has sounds as input\n",
    "#https://colab.research.google.com/github/Tyler-Hilbert/AudioProcessingInPythonWorkshop/blob/master/AudioProcessingInPython.ipynb\n",
    "#visualize the data and write code to play 2-3 sound samples in the notebook for better understanding.\n",
    "#please go through the following reference video https://www.youtube.com/watch?v=37zCgCdV468"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AA0nAtjbQLmu"
   },
   "source": [
    "## Creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.126961Z",
     "iopub.status.busy": "2023-01-26T10:26:56.126579Z",
     "iopub.status.idle": "2023-01-26T10:26:56.140618Z",
     "shell.execute_reply": "2023-01-26T10:26:56.139133Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.126918Z"
    },
    "id": "fWP6vXBeaNm3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "#You can get the label from the first letter of name.  \n",
    "#Eg: 0_jackson_0 --> 0  \n",
    "#0_jackson_43 --> 0\n",
    "label = []\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    label.append(int(i[0]))\n",
    "    \n",
    "len(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.144048Z",
     "iopub.status.busy": "2023-01-26T10:26:56.141851Z",
     "iopub.status.idle": "2023-01-26T10:26:56.158835Z",
     "shell.execute_reply": "2023-01-26T10:26:56.157949Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.143995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/spoken-digit-rec/recordings/0_yw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/spoken-digit-rec/recordings/1_yw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/spoken-digit-rec/recordings/0_ni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/spoken-digit-rec/recordings/6_ni...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/spoken-digit-rec/recordings/1_th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "0  /kaggle/input/spoken-digit-rec/recordings/0_yw...      0\n",
       "1  /kaggle/input/spoken-digit-rec/recordings/1_yw...      1\n",
       "2  /kaggle/input/spoken-digit-rec/recordings/0_ni...      0\n",
       "3  /kaggle/input/spoken-digit-rec/recordings/6_ni...      6\n",
       "4  /kaggle/input/spoken-digit-rec/recordings/1_th...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio = pd.DataFrame({'path' : all_files, 'label' : label})\n",
    "df_audio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.160594Z",
     "iopub.status.busy": "2023-01-26T10:26:56.160152Z",
     "iopub.status.idle": "2023-01-26T10:26:56.177616Z",
     "shell.execute_reply": "2023-01-26T10:26:56.176520Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.160553Z"
    },
    "id": "5ZpuaGuJaNm8",
    "outputId": "76da0fb5-2033-49ef-eba7-880c395cf87a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    2000 non-null   object\n",
      " 1   label   2000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#info\n",
    "df_audio.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOKpYJ_LaNnD"
   },
   "source": [
    "<font size=4>Grader function 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.180743Z",
     "iopub.status.busy": "2023-01-26T10:26:56.179792Z",
     "iopub.status.idle": "2023-01-26T10:26:56.191408Z",
     "shell.execute_reply": "2023-01-26T10:26:56.190364Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.180705Z"
    },
    "id": "7Q8r_T8-aNnE",
    "outputId": "849e3f3e-e77c-492c-ba29-77508e74fc57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_df():\n",
    "    flag_shape = df_audio.shape==(2000,2)\n",
    "    flag_columns = all(df_audio.columns==['path', 'label'])\n",
    "    list_values = list(df_audio.label.value_counts())\n",
    "    flag_label = len(list_values)==10\n",
    "    flag_label2 = all([i==200 for i in list_values])\n",
    "    final_flag = flag_shape and flag_columns and flag_label and flag_label2\n",
    "    return final_flag\n",
    "grader_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.193366Z",
     "iopub.status.busy": "2023-01-26T10:26:56.192927Z",
     "iopub.status.idle": "2023-01-26T10:26:56.203384Z",
     "shell.execute_reply": "2023-01-26T10:26:56.202388Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.193328Z"
    },
    "id": "PlfssCc3aNnL"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ448aENaNnR"
   },
   "source": [
    "<pre><font size=4>Train and Validation split</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.205561Z",
     "iopub.status.busy": "2023-01-26T10:26:56.205128Z",
     "iopub.status.idle": "2023-01-26T10:26:56.218847Z",
     "shell.execute_reply": "2023-01-26T10:26:56.217479Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.205471Z"
    },
    "id": "vSPy-Ln6aNnS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1400,), (600,), (1400,), (600,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into train and validation and save in X_train, X_test, y_train, y_test\n",
    "#use stratify sampling\n",
    "#use random state of 45\n",
    "#use test size of 30%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_audio['path']\n",
    "y = df_audio['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=45)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPK3sbzUaNnW"
   },
   "source": [
    "<font size=4>Grader function 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.221468Z",
     "iopub.status.busy": "2023-01-26T10:26:56.221083Z",
     "iopub.status.idle": "2023-01-26T10:26:56.233217Z",
     "shell.execute_reply": "2023-01-26T10:26:56.232079Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.221407Z"
    },
    "id": "chZzntKUaNnX",
    "outputId": "e2949c8b-2f00-434f-8403-56b577faf04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_split():\n",
    "    flag_len = (len(X_train)==1400) and (len(X_test)==600) and (len(y_train)==1400) and (len(y_test)==600)\n",
    "    values_ytrain = list(y_train.value_counts())\n",
    "    flag_ytrain = (len(values_ytrain)==10) and (all([i==140 for i in values_ytrain]))\n",
    "    values_ytest = list(y_test.value_counts())\n",
    "    flag_ytest = (len(values_ytest)==10) and (all([i==60 for i in values_ytest]))\n",
    "    final_flag = flag_len and flag_ytrain and flag_ytest\n",
    "    return final_flag\n",
    "grader_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGhh-39vaNnb"
   },
   "source": [
    "<pre><font size=4>Preprocessing</font>\n",
    "\n",
    "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.235573Z",
     "iopub.status.busy": "2023-01-26T10:26:56.235064Z",
     "iopub.status.idle": "2023-01-26T10:26:56.244019Z",
     "shell.execute_reply": "2023-01-26T10:26:56.242929Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.235537Z"
    },
    "id": "i99JacQSaNnc"
   },
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "def load_wav(x, get_duration=True):\n",
    "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
    "    #loading the wav file with sampling rate of 22050\n",
    "    samples, sample_rate = librosa.load(x, sr=22050)\n",
    "    if get_duration:\n",
    "        duration = librosa.get_duration(samples, sample_rate)\n",
    "        return [samples, duration]\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:26:56.250276Z",
     "iopub.status.busy": "2023-01-26T10:26:56.249943Z",
     "iopub.status.idle": "2023-01-26T10:27:53.983903Z",
     "shell.execute_reply": "2023-01-26T10:27:53.982822Z",
     "shell.execute_reply.started": "2023-01-26T10:26:56.250249Z"
    },
    "id": "Rx97f8GGaNnh"
   },
   "outputs": [],
   "source": [
    "#use load_wav function that was written above to get every wave. \n",
    "#save it in X_train_processed and X_test_processed\n",
    "# X_train_processed/X_test_processed should be dataframes with two columns(raw_data, duration) with same index of X_train/y_train\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_samples = []\n",
    "train_duration = []\n",
    "test_samples = []\n",
    "test_duration = []\n",
    "\n",
    "for i in X_train:\n",
    "    train_samples.append(np.array(load_wav(i)[0]))\n",
    "    train_duration.append(load_wav(i)[1])\n",
    "    \n",
    "for j in X_test:\n",
    "    test_samples.append(np.array(load_wav(j)[0]))\n",
    "    test_duration.append(load_wav(j)[1])\n",
    "    \n",
    "X_train_processed = pd.DataFrame({'raw_data' : train_samples, 'duration' : train_duration})\n",
    "X_test_processed = pd.DataFrame({'raw_data' : test_samples, 'duration' : test_duration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:27:53.985930Z",
     "iopub.status.busy": "2023-01-26T10:27:53.985568Z",
     "iopub.status.idle": "2023-01-26T10:27:54.191876Z",
     "shell.execute_reply": "2023-01-26T10:27:54.191018Z",
     "shell.execute_reply.started": "2023-01-26T10:27:53.985900Z"
    },
    "id": "duQZPQevaNno",
    "outputId": "05986007-6321-4b26-99f6-2197b1811a24"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the histogram of the duration for train\n",
    "plt.hist(X_train_processed['duration'])\n",
    "plt.grid()\n",
    "plt.title('Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:27:54.193580Z",
     "iopub.status.busy": "2023-01-26T10:27:54.193274Z",
     "iopub.status.idle": "2023-01-26T10:27:54.426378Z",
     "shell.execute_reply": "2023-01-26T10:27:54.420068Z",
     "shell.execute_reply.started": "2023-01-26T10:27:54.193553Z"
    },
    "id": "wE5SDRzSaNns",
    "outputId": "f2501a90-2a43-43db-f02c-1463defe2146"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the histogram of the duration for test\n",
    "plt.hist(X_test_processed['duration'])\n",
    "plt.grid()\n",
    "plt.title('Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:27:54.433423Z",
     "iopub.status.busy": "2023-01-26T10:27:54.431595Z",
     "iopub.status.idle": "2023-01-26T10:27:54.449738Z",
     "shell.execute_reply": "2023-01-26T10:27:54.448645Z",
     "shell.execute_reply.started": "2023-01-26T10:27:54.433347Z"
    },
    "id": "vvLhm1AqaNny",
    "outputId": "a4430992-0f16-4d24-de92-0a6fcec1df06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th percentile is  0.1435374149659864\n",
      "10 th percentile is  0.2591020408163265\n",
      "20 th percentile is  0.297750566893424\n",
      "30 th percentile is  0.33048072562358277\n",
      "40 th percentile is  0.35586394557823126\n",
      "50 th percentile is  0.38589569160997733\n",
      "60 th percentile is  0.413124716553288\n",
      "70 th percentile is  0.4444671201814059\n",
      "80 th percentile is  0.4813424036281179\n",
      "90 th percentile is  0.5528934240362812\n",
      "100 th percentile is  2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "#print 0 to 100 percentile values with step size of 10 for train data duration. \n",
    "for i in range(0, 101, 10):\n",
    "    p = np.percentile(X_train_processed['duration'], i)\n",
    "    print(i, 'th percentile is ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:27:54.451795Z",
     "iopub.status.busy": "2023-01-26T10:27:54.451345Z",
     "iopub.status.idle": "2023-01-26T10:27:54.461674Z",
     "shell.execute_reply": "2023-01-26T10:27:54.460476Z",
     "shell.execute_reply.started": "2023-01-26T10:27:54.451758Z"
    },
    "id": "rSlVQh4CaNn2",
    "outputId": "d6970436-db83-4d01-c910-7ebe92baab41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 th percentile is  0.5528934240362812\n",
      "91 th percentile is  0.561917006802721\n",
      "92 th percentile is  0.5759256235827664\n",
      "93 th percentile is  0.5915578231292521\n",
      "94 th percentile is  0.6101587301587301\n",
      "95 th percentile is  0.622421768707483\n",
      "96 th percentile is  0.6385142857142857\n",
      "97 th percentile is  0.6582875283446712\n",
      "98 th percentile is  0.6883972789115647\n",
      "99 th percentile is  0.7654394557823128\n",
      "100 th percentile is  2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "# print 90 to 100 percentile values with step size of 1. \n",
    "for i in range(90, 101):\n",
    "    p = np.percentile(X_train_processed['duration'], i)\n",
    "    print(i, 'th percentile is ', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbMb4Y0RaNoA"
   },
   "source": [
    "<font size=4>Grader function 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:27:54.463841Z",
     "iopub.status.busy": "2023-01-26T10:27:54.463422Z",
     "iopub.status.idle": "2023-01-26T10:27:54.472766Z",
     "shell.execute_reply": "2023-01-26T10:27:54.471655Z",
     "shell.execute_reply.started": "2023-01-26T10:27:54.463803Z"
    },
    "id": "UMoyLLSAaNoF",
    "outputId": "cfb3ad33-3dc0-49e7-d078-8619b164b5db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_processed():\n",
    "    flag_columns = (all(X_train_processed.columns==['raw_data', 'duration'])) and (all(X_test_processed.columns==['raw_data', 'duration']))\n",
    "    flag_shape = (X_train_processed.shape ==(1400, 2)) and (X_test_processed.shape==(600,2))\n",
    "    return flag_columns and flag_shape\n",
    "grader_processed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cux3_jfcaNoM"
   },
   "source": [
    "<b>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset.</b>\n",
    "\n",
    "<b>While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
    "</b>\n",
    "<b>Pad with Zero if length of sequence is less than 17640 else Truncate the number. </b>\n",
    "\n",
    "<b> Also create a masking vector for train and test. </b>\n",
    "\n",
    "<b> masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:27:54.474736Z",
     "iopub.status.busy": "2023-01-26T10:27:54.474354Z",
     "iopub.status.idle": "2023-01-26T10:27:54.482184Z",
     "shell.execute_reply": "2023-01-26T10:27:54.481307Z",
     "shell.execute_reply.started": "2023-01-26T10:27:54.474700Z"
    },
    "id": "voqSEyvcaNoO"
   },
   "outputs": [],
   "source": [
    "max_length  = 17640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:27:54.483746Z",
     "iopub.status.busy": "2023-01-26T10:27:54.483481Z",
     "iopub.status.idle": "2023-01-26T10:28:00.517103Z",
     "shell.execute_reply": "2023-01-26T10:28:00.516077Z",
     "shell.execute_reply.started": "2023-01-26T10:27:54.483720Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:06<00:00, 232.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X_train_pad_seq = []  \n",
    "X_train_mask = []        \n",
    "\n",
    "for i in tqdm(range(X_train_processed.shape[0])):\n",
    "    if len(X_train_processed['raw_data'].values[i]) > max_length:\n",
    "        pad = X_train_processed['raw_data'].values[i].tolist()[:max_length]\n",
    "        \n",
    "    else:\n",
    "        pad = X_train_processed['raw_data'].values[i].tolist() + [0 for j in range(max_length - len(X_train_processed['raw_data'].values[i]))] \n",
    "        \n",
    "  \n",
    "    mask=[0 if i==0 else 1 for i in pad]\n",
    "    mask=[bool(i) for i in mask]\n",
    "    X_train_pad_seq.append(pad)\n",
    "    X_train_mask.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:28:00.520343Z",
     "iopub.status.busy": "2023-01-26T10:28:00.520047Z",
     "iopub.status.idle": "2023-01-26T10:28:08.049184Z",
     "shell.execute_reply": "2023-01-26T10:28:08.048059Z",
     "shell.execute_reply.started": "2023-01-26T10:28:00.520316Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 230.66it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_pad_seq = []  \n",
    "X_test_mask = []        \n",
    "\n",
    "for i in tqdm(range(X_test_processed.shape[0])):\n",
    "    if len(X_test_processed['raw_data'].values[i]) > max_length:\n",
    "        pad = X_test_processed['raw_data'].values[i].tolist()[:max_length]\n",
    "        \n",
    "    else:\n",
    "        pad = X_test_processed['raw_data'].values[i].tolist() + [0 for j in range(max_length - len(X_test_processed['raw_data'].values[i]))] \n",
    "        \n",
    "  \n",
    "    mask=[0 if i==0 else 1 for x in pad]\n",
    "    mask=[bool(i) for i in mask]\n",
    "    X_test_pad_seq.append(pad)\n",
    "    X_test_mask.append(mask)\n",
    "\n",
    "X_train_pad_seq = np.array(X_train_pad_seq)\n",
    "X_train_mask = np.array(X_train_mask)\n",
    "X_test_pad_seq = np.array(X_test_pad_seq)\n",
    "X_test_mask = np.array(X_test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEHMgm4DaNoe"
   },
   "source": [
    "<font size=4>Grader function 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:28:08.051195Z",
     "iopub.status.busy": "2023-01-26T10:28:08.050789Z",
     "iopub.status.idle": "2023-01-26T10:28:08.060354Z",
     "shell.execute_reply": "2023-01-26T10:28:08.059398Z",
     "shell.execute_reply.started": "2023-01-26T10:28:08.051155Z"
    },
    "id": "Th3KhplGaNof",
    "outputId": "5e783ec9-81d2-4156-9e88-efdee0ff8b2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_padoutput():\n",
    "    flag_padshape = (X_train_pad_seq.shape==(1400, 17640)) and (X_test_pad_seq.shape==(600, 17640)) and (y_train.shape==(1400,))\n",
    "    flag_maskshape = (X_train_mask.shape==(1400, 17640)) and (X_test_mask.shape==(600, 17640)) and (y_test.shape==(600,))\n",
    "    flag_dtype = (X_train_mask.dtype==bool) and (X_test_mask.dtype==bool)\n",
    "    return flag_padshape and flag_maskshape and flag_dtype\n",
    "grader_padoutput()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0kaYQ1jaNop"
   },
   "source": [
    "### 1. Giving Raw data directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGHxh3jTaNoq"
   },
   "source": [
    "\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_pad_seq, X_train_mask and y_train  \n",
    "Test data: X_test_pad_seq, X_test_mask and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_pad_seq\" as input, \"X_train_mask\" as mask input. You can use any number of LSTM cells. Please read LSTM documentation(https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) in tensorflow to know more about mask and also https://www.tensorflow.org/guide/keras/masking_and_padding \n",
    "2. Get the final output of the LSTM and give it to Dense layer of any size and then give it to Dense layer of size 10(because we have 10 outputs) and then compile with the sparse categorical cross entropy( because we are not converting it to one hot vectors). Also check the datatype of class labels(y_values) and make sure that you convert your class labels  to integer datatype before fitting in the model.\n",
    "3. While defining your model make sure that you pass both the input layer and mask input layer as input to lstm layer as follows\n",
    "<img src='https://i.imgur.com/FvcgvbY.jpg'>\n",
    "4. Use tensorboard to plot the graphs of loss and metric(use custom micro F1 score as metric) and histograms of gradients. You can write your code for computing F1 score using this <a  href='https://i.imgur.com/8YULUcu.jpg'>link</a> \n",
    "\n",
    "5. make sure that it won't overfit. \n",
    "6. You are free to include any regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:28:08.062470Z",
     "iopub.status.busy": "2023-01-26T10:28:08.061761Z",
     "iopub.status.idle": "2023-01-26T10:28:09.750178Z",
     "shell.execute_reply": "2023-01-26T10:28:09.749051Z",
     "shell.execute_reply.started": "2023-01-26T10:28:08.062430Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class Score(tf.keras.callbacks.Callback):        \n",
    "    \n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.f1 = []\n",
    "        self.val_f1 = []\n",
    "     \n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        pred_train = np.argmax(self.model.predict([X_train_pad_seq,X_train_mask]),axis=1)\n",
    "        pred_test = np.argmax(self.model.predict([X_test_pad_seq,X_test_mask]),axis=1)\n",
    "        \n",
    "        train_f1 = f1_score(y_train, pred_train, average=\"micro\")\n",
    "        test_f1 = f1_score(y_test, pred_test, average=\"micro\")\n",
    "        \n",
    "        print(\"f1_score: \",train_f1, \" - val_f1_score: \", test_f1)\n",
    "        \n",
    "        self.f1.append(train_f1)\n",
    "        self.val_f1.append(test_f1)\n",
    "\n",
    "f1 = Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:28:09.757907Z",
     "iopub.status.busy": "2023-01-26T10:28:09.755092Z",
     "iopub.status.idle": "2023-01-26T10:28:09.767142Z",
     "shell.execute_reply": "2023-01-26T10:28:09.766078Z",
     "shell.execute_reply.started": "2023-01-26T10:28:09.757865Z"
    },
    "id": "X8yg951AaNor"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:28:09.768747Z",
     "iopub.status.busy": "2023-01-26T10:28:09.768409Z",
     "iopub.status.idle": "2023-01-26T10:28:11.583183Z",
     "shell.execute_reply": "2023-01-26T10:28:11.582250Z",
     "shell.execute_reply.started": "2023-01-26T10:28:09.768709Z"
    },
    "id": "d8y1sgeVaNoy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:28:09.837190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:09.847241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:09.848022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:09.849508: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-26 10:28:09.849829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:09.850566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:09.851296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:10.300527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:10.301434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:10.302122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 10:28:10.302737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 17640, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 17640)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 75)           23100       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           2432        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           170         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,358\n",
      "Trainable params: 26,294\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## as discussed above, please write the architecture of the model.\n",
    "## you will have two input layers in your model (data input layer and mask input layer)\n",
    "## make sure that you have defined the data type of masking layer as bool\n",
    "## as discussed above, please write the LSTM\n",
    "\n",
    "input_layer = Input(shape=(17640,1))\n",
    "mask_input = Input(shape=(17640,), dtype=bool)\n",
    "\n",
    "LSTM_layer = LSTM(75)(inputs=input_layer, mask=mask_input)\n",
    "\n",
    "dense_1 = Dense(32)(LSTM_layer)\n",
    "drop = Dropout(0.5)(dense_1)\n",
    "bn = BatchNormalization()(drop)\n",
    "\n",
    "dense_2 = Dense(16)(bn)\n",
    "output = Dense(10, activation=\"softmax\")(dense_2)\n",
    "\n",
    "model_1 = Model(inputs=[input_layer, mask_input],outputs=[output])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:28:11.590384Z",
     "iopub.status.busy": "2023-01-26T10:28:11.587477Z",
     "iopub.status.idle": "2023-01-26T10:28:13.085321Z",
     "shell.execute_reply": "2023-01-26T10:28:13.084103Z",
     "shell.execute_reply.started": "2023-01-26T10:28:11.590346Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:28:12.766270: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-01-26 10:28:12.766328: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2023-01-26 10:28:12.766411: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2023-01-26 10:28:12.958704: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-01-26 10:28:12.958880: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "! rm -rf ./logs/ \n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:28:13.088075Z",
     "iopub.status.busy": "2023-01-26T10:28:13.087410Z",
     "iopub.status.idle": "2023-01-26T10:28:13.106751Z",
     "shell.execute_reply": "2023-01-26T10:28:13.105738Z",
     "shell.execute_reply.started": "2023-01-26T10:28:13.088030Z"
    },
    "id": "MzpPjxvHaNpJ"
   },
   "outputs": [],
   "source": [
    "model_1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:28:13.109529Z",
     "iopub.status.busy": "2023-01-26T10:28:13.109264Z",
     "iopub.status.idle": "2023-01-26T10:30:13.386530Z",
     "shell.execute_reply": "2023-01-26T10:30:13.385462Z",
     "shell.execute_reply.started": "2023-01-26T10:28:13.109504Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:28:13.400608: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:28:16.786145: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/44 [..............................] - ETA: 3:17 - loss: 2.3025 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:28:18.109160: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-01-26 10:28:18.109207: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/44 [>.............................] - ETA: 47s - loss: 2.2925 - accuracy: 0.1406 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:28:19.142504: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-01-26 10:28:19.188995: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2023-01-26 10:28:19.323793: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 64623 callback api events and 64620 activity events. \n",
      "2023-01-26 10:28:20.441335: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-01-26 10:28:22.620372: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20\n",
      "\n",
      "2023-01-26 10:28:23.803629: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20/5dfbba354824.trace.json.gz\n",
      "2023-01-26 10:28:24.604936: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20\n",
      "\n",
      "2023-01-26 10:28:24.607966: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20/5dfbba354824.memory_profile.json.gz\n",
      "2023-01-26 10:28:24.620651: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20\n",
      "Dumped tool data for xplane.pb to logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20/5dfbba354824.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20/5dfbba354824.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20/5dfbba354824.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20/5dfbba354824.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20230126-102812/train/plugins/profile/2023_01_26_10_28_20/5dfbba354824.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 46s 975ms/step - loss: 2.3310 - accuracy: 0.1129 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "f1_score:  0.10000000000000002  - val_f1_score:  0.10000000000000002\n",
      "Epoch 2/2\n",
      "44/44 [==============================] - 34s 780ms/step - loss: 2.3248 - accuracy: 0.1029 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "f1_score:  0.10285714285714286  - val_f1_score:  0.10000000000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2bcec13f90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_lst = [f1, tensorboard_callback]\n",
    "model_1.fit([X_train_pad_seq,X_train_mask],y_train, epochs=2, validation_data=([X_test_pad_seq,X_test_mask],y_test), batch_size=32, callbacks=callback_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:13.389041Z",
     "iopub.status.busy": "2023-01-26T10:30:13.388157Z",
     "iopub.status.idle": "2023-01-26T10:30:16.503288Z",
     "shell.execute_reply": "2023-01-26T10:30:16.502020Z",
     "shell.execute_reply.started": "2023-01-26T10:30:13.388983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-254dd979d77df05f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-254dd979d77df05f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fwk0X4zaNpR"
   },
   "source": [
    "### 2. Converting into spectrogram and giving spectrogram data as input  \n",
    "\n",
    "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
    "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. you can read more about this in https://pnsn.org/spectrograms/what-is-a-spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:16.505899Z",
     "iopub.status.busy": "2023-01-26T10:30:16.505449Z",
     "iopub.status.idle": "2023-01-26T10:30:16.512058Z",
     "shell.execute_reply": "2023-01-26T10:30:16.510934Z",
     "shell.execute_reply.started": "2023-01-26T10:30:16.505845Z"
    },
    "id": "nb5AGzTjaNpS"
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:16.514378Z",
     "iopub.status.busy": "2023-01-26T10:30:16.513420Z",
     "iopub.status.idle": "2023-01-26T10:30:29.694099Z",
     "shell.execute_reply": "2023-01-26T10:30:29.692305Z",
     "shell.execute_reply.started": "2023-01-26T10:30:16.514338Z"
    },
    "id": "B__rN4RjaNpc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:09<00:00, 152.99it/s]\n",
      "100%|██████████| 600/600 [00:03<00:00, 151.55it/s]\n"
     ]
    }
   ],
   "source": [
    "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad-seq.\n",
    "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
    "X_train_spectrogram = []\n",
    "X_test_spectrogram = []\n",
    "\n",
    "for i in tqdm(X_train_pad_seq):\n",
    "    X_train_spectrogram.append(convert_to_spectrogram(i))\n",
    "    \n",
    "for j in tqdm(X_test_pad_seq):\n",
    "    X_test_spectrogram.append(convert_to_spectrogram(j))\n",
    "    \n",
    "X_train_spectrogram = np.array(X_train_spectrogram)\n",
    "X_test_spectrogram = np.array(X_test_spectrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr1ynYZnaNpj"
   },
   "source": [
    "<font size=4>Grader function 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:29.696024Z",
     "iopub.status.busy": "2023-01-26T10:30:29.695592Z",
     "iopub.status.idle": "2023-01-26T10:30:29.707997Z",
     "shell.execute_reply": "2023-01-26T10:30:29.706563Z",
     "shell.execute_reply.started": "2023-01-26T10:30:29.695966Z"
    },
    "id": "oniXBXcsaNpk",
    "outputId": "0f94ec35-98af-4b98-c501-35cbbfbd0a2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_spectrogram():\n",
    "    flag_shape = (X_train_spectrogram.shape==(1400,64, 35)) and (X_test_spectrogram.shape == (600, 64, 35))\n",
    "    return flag_shape\n",
    "grader_spectrogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxlEVyIYaNpt"
   },
   "source": [
    "\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_spectrogram and y_train  \n",
    "Test data: X_test_spectrogram and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
    "2. Average the output of every time step and give this to the Dense layer of any size. \n",
    "(ex: Output from LSTM will be  (None, time_steps, features) average the output of every time step i.e, you should get (None,time_steps) \n",
    "and then pass to dense layer )\n",
    "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy.  \n",
    "4. Use tensorboard to plot the graphs of loss and metric(use custom micro F1 score as metric) and histograms of gradients. You can write your code for computing F1 score using this <a  href='https://i.imgur.com/8YULUcu.jpg'>link</a> \n",
    "5. make sure that it won't overfit. \n",
    "6. You are free to include any regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:29.709730Z",
     "iopub.status.busy": "2023-01-26T10:30:29.709126Z",
     "iopub.status.idle": "2023-01-26T10:30:29.723311Z",
     "shell.execute_reply": "2023-01-26T10:30:29.722275Z",
     "shell.execute_reply.started": "2023-01-26T10:30:29.709683Z"
    }
   },
   "outputs": [],
   "source": [
    "class Score(tf.keras.callbacks.Callback):        \n",
    "    \n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.f1 = []\n",
    "        self.val_f1 = []\n",
    "     \n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        pred_train = np.argmax(self.model.predict(X_train_spectrogram),axis=1)\n",
    "        pred_test = np.argmax(self.model.predict(X_test_spectrogram),axis=1)\n",
    "        \n",
    "        train_f1 = f1_score(y_train, pred_train, average=\"micro\")\n",
    "        test_f1 = f1_score(y_test, pred_test, average=\"micro\")\n",
    "        \n",
    "        print(\"f1_score: \",train_f1, \" - val_f1_score: \", test_f1)\n",
    "        \n",
    "        self.f1.append(train_f1)\n",
    "        self.val_f1.append(test_f1)\n",
    "\n",
    "f1 = Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:29.725329Z",
     "iopub.status.busy": "2023-01-26T10:30:29.724674Z",
     "iopub.status.idle": "2023-01-26T10:30:30.061950Z",
     "shell.execute_reply": "2023-01-26T10:30:30.060955Z",
     "shell.execute_reply.started": "2023-01-26T10:30:29.725293Z"
    },
    "id": "IaQjaiiGaNpv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64, 35)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64, 256)           299008    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 318,250\n",
      "Trainable params: 318,122\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Dropout\n",
    "\n",
    "input_layer = Input(shape=(64, 35))\n",
    "\n",
    "LSTM_layer = LSTM(256, activation=\"tanh\", return_sequences=True)(input_layer)\n",
    "pool = GlobalAveragePooling1D(data_format=\"channels_first\")(LSTM_layer)\n",
    "\n",
    "dense_1 = Dense(128, activation=\"relu\")(pool)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "\n",
    "dense_2 = Dense(64, activation=\"relu\")(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(dense_2)\n",
    "bn = BatchNormalization()(dropout_2)\n",
    "\n",
    "dense_3 = Dense(32,activation='relu')(bn)\n",
    "output = Dense(10,activation=\"softmax\")(dense_3)\n",
    "\n",
    "model_2=Model(inputs=[input_layer],outputs=[output])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:30.064151Z",
     "iopub.status.busy": "2023-01-26T10:30:30.063783Z",
     "iopub.status.idle": "2023-01-26T10:30:31.514498Z",
     "shell.execute_reply": "2023-01-26T10:30:31.513092Z",
     "shell.execute_reply.started": "2023-01-26T10:30:30.064114Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:30:31.102760: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-01-26 10:30:31.102826: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2023-01-26 10:30:31.382313: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-01-26 10:30:31.382501: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "! rm -rf ./logs/ \n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:31.517689Z",
     "iopub.status.busy": "2023-01-26T10:30:31.516530Z",
     "iopub.status.idle": "2023-01-26T10:30:31.530770Z",
     "shell.execute_reply": "2023-01-26T10:30:31.529861Z",
     "shell.execute_reply.started": "2023-01-26T10:30:31.517635Z"
    },
    "id": "862fP2e-aNp3"
   },
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:31.532754Z",
     "iopub.status.busy": "2023-01-26T10:30:31.532140Z",
     "iopub.status.idle": "2023-01-26T10:30:53.561859Z",
     "shell.execute_reply": "2023-01-26T10:30:53.560834Z",
     "shell.execute_reply.started": "2023-01-26T10:30:31.532715Z"
    },
    "id": "VtMsbGs3aNp_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 1/44 [..............................] - ETA: 1:09 - loss: 2.2810 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:30:33.318449: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-01-26 10:30:33.318887: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/44 [=>............................] - ETA: 13s - loss: 2.3153 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:30:33.685577: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-01-26 10:30:33.686467: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2023-01-26 10:30:33.822451: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 501 callback api events and 498 activity events. \n",
      "2023-01-26 10:30:33.832489: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-01-26 10:30:33.845118: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33\n",
      "\n",
      "2023-01-26 10:30:33.853848: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33/5dfbba354824.trace.json.gz\n",
      "2023-01-26 10:30:33.866639: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33\n",
      "\n",
      "2023-01-26 10:30:33.869339: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33/5dfbba354824.memory_profile.json.gz\n",
      "2023-01-26 10:30:33.870124: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33\n",
      "Dumped tool data for xplane.pb to logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33/5dfbba354824.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33/5dfbba354824.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33/5dfbba354824.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33/5dfbba354824.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20230126-103031/train/plugins/profile/2023_01_26_10_30_33/5dfbba354824.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 3s 34ms/step - loss: 2.1802 - accuracy: 0.1621 - val_loss: 2.2751 - val_accuracy: 0.1867\n",
      "f1_score:  0.19928571428571426  - val_f1_score:  0.18666666666666668\n",
      "Epoch 2/25\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 1.8474 - accuracy: 0.2900 - val_loss: 2.2035 - val_accuracy: 0.2900\n",
      "f1_score:  0.2885714285714286  - val_f1_score:  0.29\n",
      "Epoch 3/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.5402 - accuracy: 0.4121 - val_loss: 2.1252 - val_accuracy: 0.3183\n",
      "f1_score:  0.31857142857142856  - val_f1_score:  0.31833333333333336\n",
      "Epoch 4/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.3362 - accuracy: 0.5271 - val_loss: 1.9723 - val_accuracy: 0.5283\n",
      "f1_score:  0.5064285714285715  - val_f1_score:  0.5283333333333333\n",
      "Epoch 5/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.1900 - accuracy: 0.5636 - val_loss: 1.8664 - val_accuracy: 0.4400\n",
      "f1_score:  0.43214285714285716  - val_f1_score:  0.44\n",
      "Epoch 6/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.0246 - accuracy: 0.6114 - val_loss: 1.7050 - val_accuracy: 0.4650\n",
      "f1_score:  0.47285714285714286  - val_f1_score:  0.465\n",
      "Epoch 7/25\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.9372 - accuracy: 0.6443 - val_loss: 1.4740 - val_accuracy: 0.6800\n",
      "f1_score:  0.6878571428571428  - val_f1_score:  0.68\n",
      "Epoch 8/25\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.8795 - accuracy: 0.6614 - val_loss: 1.2664 - val_accuracy: 0.7350\n",
      "f1_score:  0.7299999999999999  - val_f1_score:  0.735\n",
      "Epoch 9/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.8316 - accuracy: 0.6821 - val_loss: 1.0632 - val_accuracy: 0.7617\n",
      "f1_score:  0.7514285714285714  - val_f1_score:  0.7616666666666667\n",
      "Epoch 10/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7767 - accuracy: 0.6979 - val_loss: 0.9145 - val_accuracy: 0.7950\n",
      "f1_score:  0.7778571428571428  - val_f1_score:  0.795\n",
      "Epoch 11/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7743 - accuracy: 0.7107 - val_loss: 0.8588 - val_accuracy: 0.8083\n",
      "f1_score:  0.7914285714285715  - val_f1_score:  0.8083333333333333\n",
      "Epoch 12/25\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.7066 - accuracy: 0.7264 - val_loss: 0.6698 - val_accuracy: 0.8333\n",
      "f1_score:  0.8278571428571427  - val_f1_score:  0.8333333333333334\n",
      "Epoch 13/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7214 - accuracy: 0.7264 - val_loss: 0.6068 - val_accuracy: 0.8467\n",
      "f1_score:  0.825  - val_f1_score:  0.8466666666666667\n",
      "Epoch 14/25\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.7283 - accuracy: 0.7336 - val_loss: 0.5781 - val_accuracy: 0.8417\n",
      "f1_score:  0.8321428571428572  - val_f1_score:  0.8416666666666667\n",
      "Epoch 15/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7234 - accuracy: 0.7343 - val_loss: 0.5425 - val_accuracy: 0.8233\n",
      "f1_score:  0.81  - val_f1_score:  0.8233333333333334\n",
      "Epoch 16/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7614 - accuracy: 0.7057 - val_loss: 0.5993 - val_accuracy: 0.7983\n",
      "f1_score:  0.7935714285714286  - val_f1_score:  0.7983333333333333\n",
      "Epoch 17/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7310 - accuracy: 0.7264 - val_loss: 0.4960 - val_accuracy: 0.8367\n",
      "f1_score:  0.8257142857142856  - val_f1_score:  0.8366666666666667\n",
      "Epoch 18/25\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.7040 - accuracy: 0.7286 - val_loss: 0.4115 - val_accuracy: 0.8617\n",
      "f1_score:  0.8514285714285714  - val_f1_score:  0.8616666666666667\n",
      "Epoch 19/25\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.6659 - accuracy: 0.7471 - val_loss: 0.3876 - val_accuracy: 0.8600\n",
      "f1_score:  0.8557142857142858  - val_f1_score:  0.8599999999999999\n",
      "Epoch 20/25\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.6298 - accuracy: 0.7614 - val_loss: 0.3660 - val_accuracy: 0.8883\n",
      "f1_score:  0.865  - val_f1_score:  0.8883333333333333\n",
      "Epoch 21/25\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.7350 - val_loss: 0.4140 - val_accuracy: 0.8467\n",
      "f1_score:  0.8485714285714285  - val_f1_score:  0.8466666666666667\n",
      "Epoch 22/25\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 0.7097 - accuracy: 0.7314 - val_loss: 0.4197 - val_accuracy: 0.8383\n",
      "f1_score:  0.8428571428571429  - val_f1_score:  0.8383333333333334\n",
      "Epoch 23/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7273 - accuracy: 0.7279 - val_loss: 0.4037 - val_accuracy: 0.8500\n",
      "f1_score:  0.8742857142857143  - val_f1_score:  0.85\n",
      "Epoch 24/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7485 - accuracy: 0.7107 - val_loss: 0.5024 - val_accuracy: 0.8283\n",
      "f1_score:  0.8271428571428572  - val_f1_score:  0.8283333333333334\n",
      "Epoch 25/25\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7138 - accuracy: 0.7386 - val_loss: 0.3987 - val_accuracy: 0.8800\n",
      "f1_score:  0.8592857142857143  - val_f1_score:  0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2bcc3f6e10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_lst = [f1, tensorboard_callback]\n",
    "model_2.fit(X_train_spectrogram, y_train, epochs=25, validation_data=(X_test_spectrogram, y_test), batch_size=32, callbacks=callback_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:53.564246Z",
     "iopub.status.busy": "2023-01-26T10:30:53.563378Z",
     "iopub.status.idle": "2023-01-26T10:30:56.679569Z",
     "shell.execute_reply": "2023-01-26T10:30:56.678478Z",
     "shell.execute_reply.started": "2023-01-26T10:30:53.564206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-abcea1e4118a7640\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-abcea1e4118a7640\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSl8ZOXjaNqJ"
   },
   "source": [
    "### 3. Data augmentation with raw features \n",
    "\n",
    "Till now we have done with 2000 samples only. It is very less data. We are giving the process of generating augmented data below.\n",
    "\n",
    "There are two types of augmentation:\n",
    "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
    "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:56.681588Z",
     "iopub.status.busy": "2023-01-26T10:30:56.681266Z",
     "iopub.status.idle": "2023-01-26T10:30:56.688508Z",
     "shell.execute_reply": "2023-01-26T10:30:56.687581Z",
     "shell.execute_reply.started": "2023-01-26T10:30:56.681557Z"
    },
    "id": "jR4JSEDgaNqK"
   },
   "outputs": [],
   "source": [
    "## generating augmented data. \n",
    "def generate_augmented_data(file_path):\n",
    "    augmented_data = []\n",
    "    samples = load_wav(file_path,get_duration=False)\n",
    "    for time_value in [0.7, 1, 1.3]:\n",
    "        for pitch_value in [-1, 0, 1]:\n",
    "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
    "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
    "            augmented_data.append(final_data)\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:56.699874Z",
     "iopub.status.busy": "2023-01-26T10:30:56.699118Z",
     "iopub.status.idle": "2023-01-26T10:30:56.947177Z",
     "shell.execute_reply": "2023-01-26T10:30:56.946173Z",
     "shell.execute_reply.started": "2023-01-26T10:30:56.699838Z"
    },
    "id": "QRdefb-SaNqS"
   },
   "outputs": [],
   "source": [
    "temp_path = df_audio.iloc[0].path\n",
    "aug_temp = generate_augmented_data(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:56.949350Z",
     "iopub.status.busy": "2023-01-26T10:30:56.948949Z",
     "iopub.status.idle": "2023-01-26T10:30:56.957118Z",
     "shell.execute_reply": "2023-01-26T10:30:56.956072Z",
     "shell.execute_reply.started": "2023-01-26T10:30:56.949309Z"
    },
    "id": "kzdG3iS-aNqc",
    "outputId": "0f17e45e-63a0-4986-8f69-05e2dbd71bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZckytZsraNqk"
   },
   "source": [
    "## Follow the steps \n",
    "\n",
    "1. Split data 'df_audio' into train and test (80-20 split)\n",
    "\n",
    "2. We have 2000 data points(1600 train points, 400 test points) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:56.959547Z",
     "iopub.status.busy": "2023-01-26T10:30:56.958589Z",
     "iopub.status.idle": "2023-01-26T10:30:56.969592Z",
     "shell.execute_reply": "2023-01-26T10:30:56.968555Z",
     "shell.execute_reply.started": "2023-01-26T10:30:56.959510Z"
    },
    "id": "LFo5SnTLO_sD"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(df_audio['path'],df_audio['label'],random_state=45,test_size=0.2,stratify=df_audio['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdKXVRlpaNql"
   },
   "source": [
    "3. Do augmentation only on X_train,pass each point of X_train to generate_augmented_data function.After augmentation we will get 14400 train points. Make sure that you are augmenting the corresponding class labels (y_train) also.\n",
    "4. Preprocess your X_test using load_wav function.\n",
    "5. Convert the augmented_train_data and test_data to numpy arrays.\n",
    "6. Perform padding and masking on augmented_train_data and test_data.\n",
    "7. After padding define the model similar to model 1 and fit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8Yh72uYO_sD"
   },
   "source": [
    "<font color='red'> Note </font> - While fitting your model on the augmented data for model 3 you might face Resource exhaust error. One simple hack to avoid that is save the augmented_train_data,augment_y_train,test_data and y_test to Drive or into your local system. Then restart the runtime so that now you can train your model with full RAM capacity. Upload these files again in the new runtime session perform padding and masking and then fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:30:56.971455Z",
     "iopub.status.busy": "2023-01-26T10:30:56.970949Z",
     "iopub.status.idle": "2023-01-26T10:35:40.627200Z",
     "shell.execute_reply": "2023-01-26T10:35:40.626073Z",
     "shell.execute_reply.started": "2023-01-26T10:30:56.971416Z"
    },
    "id": "41vU8M1gO_sD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [04:43<00:00,  5.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X_train_aug = []\n",
    "\n",
    "for i in tqdm(X_train):\n",
    "    aug = generate_augmented_data(i)\n",
    "    for j in range(9):\n",
    "        X_train_aug.append(aug[j])   \n",
    "        \n",
    "X_train_processed = pd.DataFrame()\n",
    "X_train_processed[\"raw_data\"] = X_train_aug\n",
    "        \n",
    "y_train = np.array(y_train)\n",
    "y_train = np.repeat(y_train, 9, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:35:40.629074Z",
     "iopub.status.busy": "2023-01-26T10:35:40.628589Z",
     "iopub.status.idle": "2023-01-26T10:35:44.433966Z",
     "shell.execute_reply": "2023-01-26T10:35:44.432377Z",
     "shell.execute_reply.started": "2023-01-26T10:35:40.629035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:03<00:00, 105.46it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_aug  = []\n",
    "\n",
    "for i in tqdm(X_test):\n",
    "    res = load_wav(i, get_duration=False)\n",
    "    X_test_aug.append(res)\n",
    "    \n",
    "X_test_processed = pd.DataFrame()\n",
    "X_test_processed[\"raw_data\"] = X_test_aug\n",
    "\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:35:44.436162Z",
     "iopub.status.busy": "2023-01-26T10:35:44.435301Z",
     "iopub.status.idle": "2023-01-26T10:35:44.447064Z",
     "shell.execute_reply": "2023-01-26T10:35:44.446059Z",
     "shell.execute_reply.started": "2023-01-26T10:35:44.436122Z"
    }
   },
   "outputs": [],
   "source": [
    "duration = []\n",
    "\n",
    "for i in X_train_aug:\n",
    "    duration.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:35:44.449795Z",
     "iopub.status.busy": "2023-01-26T10:35:44.448780Z",
     "iopub.status.idle": "2023-01-26T10:35:44.472526Z",
     "shell.execute_reply": "2023-01-26T10:35:44.471669Z",
     "shell.execute_reply.started": "2023-01-26T10:35:44.449756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 th percentile is  14410.100000000004\n",
      "91 th percentile is  14688.700000000004\n",
      "92 th percentile is  15026.32\n",
      "93 th percentile is  15270.280000000006\n",
      "94 th percentile is  15741.119999999999\n",
      "95 th percentile is  16274.449999999993\n",
      "96 th percentile is  17043.119999999995\n",
      "97 th percentile is  18141.0\n",
      "98 th percentile is  19373.260000000006\n",
      "99 th percentile is  20956.240000000005\n",
      "100 th percentile is  71907.0\n"
     ]
    }
   ],
   "source": [
    "# print 90 to 100 percentile values with step size of 1. \n",
    "for i in range(90, 101):\n",
    "    p = np.percentile(duration, i)\n",
    "    print(i, 'th percentile is ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:35:44.474233Z",
     "iopub.status.busy": "2023-01-26T10:35:44.473878Z",
     "iopub.status.idle": "2023-01-26T10:36:04.371434Z",
     "shell.execute_reply": "2023-01-26T10:36:04.370406Z",
     "shell.execute_reply.started": "2023-01-26T10:35:44.474197Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14400/14400 [00:19<00:00, 724.16it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_pad_seq=[]\n",
    "X_test_pad_seq=[]\n",
    "X_train_mask=[]\n",
    "X_test_mask=[]\n",
    "\n",
    "#Train data processing\n",
    "for i in tqdm(X_train_processed[\"raw_data\"].values):\n",
    "    if len(i)>max_length:\n",
    "        X_train_pad_seq.append(i[0:max_length])\n",
    "        X_train_mask.append(np.array([1]*max_length))\n",
    "    elif len(i)<max_length:\n",
    "        k=len(i)\n",
    "        i=np.pad(i,(0,max_length-k))\n",
    "        X_train_pad_seq.append(i)\n",
    "        X_train_mask.append(np.concatenate((np.array([1]*k),np.array([0]*(max_length-k)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:36:04.373713Z",
     "iopub.status.busy": "2023-01-26T10:36:04.372968Z",
     "iopub.status.idle": "2023-01-26T10:36:06.242396Z",
     "shell.execute_reply": "2023-01-26T10:36:06.241348Z",
     "shell.execute_reply.started": "2023-01-26T10:36:04.373671Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 739.09it/s]\n"
     ]
    }
   ],
   "source": [
    "#Test Data processing       \n",
    "for i in tqdm(X_test_processed[\"raw_data\"].values):\n",
    "    if len(i)>max_length:\n",
    "        X_test_pad_seq.append(i[0:max_length])\n",
    "        X_test_mask.append(np.array([1]*max_length))\n",
    "    elif len(i)<max_length:\n",
    "        k=len(i)\n",
    "        i=np.pad(i,(0,max_length-k))\n",
    "        X_test_pad_seq.append(i)\n",
    "        X_test_mask.append(np.concatenate((np.array([1]*k),np.array([0]*(max_length-k)))))\n",
    "\n",
    "X_train_pad_seq=np.array(X_train_pad_seq)\n",
    "X_test_pad_seq=np.array(X_test_pad_seq)\n",
    "X_train_mask=np.array(X_train_mask)\n",
    "X_train_mask=X_train_mask.astype(bool)\n",
    "X_test_mask=np.array(X_test_mask)\n",
    "X_test_mask=X_test_mask.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:36:06.244621Z",
     "iopub.status.busy": "2023-01-26T10:36:06.243738Z",
     "iopub.status.idle": "2023-01-26T10:36:07.008324Z",
     "shell.execute_reply": "2023-01-26T10:36:07.007292Z",
     "shell.execute_reply.started": "2023-01-26T10:36:06.244575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 17640, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 17640)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 75)           23100       input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2432        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32)           128         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           528         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           170         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,358\n",
      "Trainable params: 26,294\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(17640,1))\n",
    "mask_input = Input(shape=(17640,), dtype=bool)\n",
    "\n",
    "LSTM_layer = LSTM(75)(inputs=input_layer, mask=mask_input)\n",
    "\n",
    "dense_1 = Dense(32)(LSTM_layer)\n",
    "drop = Dropout(0.5)(dense_1)\n",
    "bn = BatchNormalization()(drop)\n",
    "\n",
    "dense_2 = Dense(16)(bn)\n",
    "output = Dense(10, activation=\"softmax\")(dense_2)\n",
    "\n",
    "model_3 = Model(inputs=[input_layer, mask_input],outputs=[output])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:36:07.010531Z",
     "iopub.status.busy": "2023-01-26T10:36:07.009902Z",
     "iopub.status.idle": "2023-01-26T10:36:08.485385Z",
     "shell.execute_reply": "2023-01-26T10:36:08.483963Z",
     "shell.execute_reply.started": "2023-01-26T10:36:07.010490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:36:08.097510: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-01-26 10:36:08.097564: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2023-01-26 10:36:08.353705: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-01-26 10:36:08.353903: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "! rm -rf ./logs/ \n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:36:08.488374Z",
     "iopub.status.busy": "2023-01-26T10:36:08.487913Z",
     "iopub.status.idle": "2023-01-26T10:36:08.497302Z",
     "shell.execute_reply": "2023-01-26T10:36:08.496219Z",
     "shell.execute_reply.started": "2023-01-26T10:36:08.488330Z"
    }
   },
   "outputs": [],
   "source": [
    "class Score(tf.keras.callbacks.Callback):        \n",
    "    \n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.f1 = []\n",
    "        self.val_f1 = []\n",
    "     \n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        pred_train = np.argmax(self.model.predict([X_train_pad_seq,X_train_mask]),axis=1)\n",
    "        pred_test = np.argmax(self.model.predict([X_test_pad_seq,X_test_mask]),axis=1)\n",
    "        \n",
    "        train_f1 = f1_score(y_train, pred_train, average=\"micro\")\n",
    "        test_f1 = f1_score(y_test, pred_test, average=\"micro\")\n",
    "        \n",
    "        print(\"f1_score: \",train_f1, \" - val_f1_score: \", test_f1)\n",
    "        \n",
    "        self.f1.append(train_f1)\n",
    "        self.val_f1.append(test_f1)\n",
    "\n",
    "f1 = Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:36:08.499596Z",
     "iopub.status.busy": "2023-01-26T10:36:08.498922Z",
     "iopub.status.idle": "2023-01-26T10:36:08.515783Z",
     "shell.execute_reply": "2023-01-26T10:36:08.514783Z",
     "shell.execute_reply.started": "2023-01-26T10:36:08.499558Z"
    }
   },
   "outputs": [],
   "source": [
    "model_3.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:36:08.518768Z",
     "iopub.status.busy": "2023-01-26T10:36:08.518049Z",
     "iopub.status.idle": "2023-01-26T10:51:34.912278Z",
     "shell.execute_reply": "2023-01-26T10:51:34.911043Z",
     "shell.execute_reply.started": "2023-01-26T10:36:08.518731Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:36:08.523804: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1016064000 exceeds 10% of free system memory.\n",
      "2023-01-26 10:36:09.884698: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1016064000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  1/450 [..............................] - ETA: 28:34 - loss: 2.3045 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:36:14.783098: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-01-26 10:36:14.783151: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/450 [..............................] - ETA: 8:55 - loss: 2.3033 - accuracy: 0.0781 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:36:15.995072: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-01-26 10:36:16.056154: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2023-01-26 10:36:16.207933: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 79784 callback api events and 79781 activity events. \n",
      "2023-01-26 10:36:17.571811: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-01-26 10:36:20.173593: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17\n",
      "\n",
      "2023-01-26 10:36:21.783260: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17/5dfbba354824.trace.json.gz\n",
      "2023-01-26 10:36:22.794806: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17\n",
      "\n",
      "2023-01-26 10:36:22.797414: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17/5dfbba354824.memory_profile.json.gz\n",
      "2023-01-26 10:36:22.813408: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17\n",
      "Dumped tool data for xplane.pb to logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17/5dfbba354824.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17/5dfbba354824.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17/5dfbba354824.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17/5dfbba354824.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20230126-103608/train/plugins/profile/2023_01_26_10_36_17/5dfbba354824.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 293s 644ms/step - loss: 2.3182 - accuracy: 0.1023 - val_loss: 2.3037 - val_accuracy: 0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:41:04.002496: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1016064000 exceeds 10% of free system memory.\n",
      "2023-01-26 10:41:04.994437: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1016064000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.10631944444444444  - val_f1_score:  0.11\n",
      "Epoch 2/2\n",
      "450/450 [==============================] - 283s 628ms/step - loss: 2.3110 - accuracy: 0.0919 - val_loss: 2.3080 - val_accuracy: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:48:14.980341: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1016064000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.10069444444444445  - val_f1_score:  0.1025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2bcbd71950>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_lst = [f1, tensorboard_callback]\n",
    "model_3.fit([X_train_pad_seq, X_train_mask], y_train, epochs=2, validation_data=([X_test_pad_seq, X_test_mask],y_test), batch_size=32, callbacks=[callback_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:51:34.913896Z",
     "iopub.status.busy": "2023-01-26T10:51:34.913594Z",
     "iopub.status.idle": "2023-01-26T10:51:38.137418Z",
     "shell.execute_reply": "2023-01-26T10:51:38.136312Z",
     "shell.execute_reply.started": "2023-01-26T10:51:34.913868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-76c034b69092c12e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-76c034b69092c12e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXY9uP7cO_sE"
   },
   "source": [
    "### 4. Data augmentation with spectogram data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EShBfiERO_sE"
   },
   "source": [
    "1. use convert_to_spectrogram and convert the padded data from train and test data to spectogram data.\n",
    "2. The shape of train data will be 14400 x 64 x 35 and shape of test_data will be 400 x 64 x35\n",
    "3. Define the model similar to model 2 and fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:51:38.140021Z",
     "iopub.status.busy": "2023-01-26T10:51:38.139582Z",
     "iopub.status.idle": "2023-01-26T10:53:01.058414Z",
     "shell.execute_reply": "2023-01-26T10:53:01.057366Z",
     "shell.execute_reply.started": "2023-01-26T10:51:38.139959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14400/14400 [01:20<00:00, 178.51it/s]\n",
      "100%|██████████| 400/400 [00:02<00:00, 192.09it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_spectrogram = []\n",
    "X_test_spectrogram = []\n",
    "\n",
    "for i in tqdm(X_train_pad_seq):\n",
    "    X_train_spectrogram.append(convert_to_spectrogram(i))\n",
    "    \n",
    "for j in tqdm(X_test_pad_seq):\n",
    "    X_test_spectrogram.append(convert_to_spectrogram(j))\n",
    "    \n",
    "X_train_spectrogram = np.array(X_train_spectrogram)\n",
    "X_test_spectrogram = np.array(X_test_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:53:01.062275Z",
     "iopub.status.busy": "2023-01-26T10:53:01.061955Z",
     "iopub.status.idle": "2023-01-26T10:53:01.069427Z",
     "shell.execute_reply": "2023-01-26T10:53:01.068451Z",
     "shell.execute_reply.started": "2023-01-26T10:53:01.062248Z"
    }
   },
   "outputs": [],
   "source": [
    "class Score(tf.keras.callbacks.Callback):        \n",
    "    \n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.f1 = []\n",
    "        self.val_f1 = []\n",
    "     \n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        pred_train = np.argmax(self.model.predict(X_train_spectrogram),axis=1)\n",
    "        pred_test = np.argmax(self.model.predict(X_test_spectrogram),axis=1)\n",
    "        \n",
    "        train_f1 = f1_score(y_train, pred_train, average=\"micro\")\n",
    "        test_f1 = f1_score(y_test, pred_test, average=\"micro\")\n",
    "        \n",
    "        print(\"f1_score: \",train_f1, \" - val_f1_score: \", test_f1)\n",
    "        \n",
    "        self.f1.append(train_f1)\n",
    "        self.val_f1.append(test_f1)\n",
    "\n",
    "f1 = Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:31.271644Z",
     "iopub.status.busy": "2023-01-26T10:54:31.271268Z",
     "iopub.status.idle": "2023-01-26T10:54:31.565235Z",
     "shell.execute_reply": "2023-01-26T10:54:31.563273Z",
     "shell.execute_reply.started": "2023-01-26T10:54:31.271613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 64, 35)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64, 256)           299008    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 318,250\n",
      "Trainable params: 318,122\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.activations import selu\n",
    "input_layer = Input(shape=(64, 35))\n",
    "\n",
    "LSTM_layer = LSTM(256, activation=\"tanh\", return_sequences=True)(input_layer)\n",
    "pool = GlobalAveragePooling1D(data_format=\"channels_first\")(LSTM_layer)\n",
    "\n",
    "dense_1 = Dense(128, activation=\"selu\")(pool)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "\n",
    "dense_2 = Dense(64, activation=\"selu\")(dropout_1)\n",
    "bn = BatchNormalization()(dense_2)\n",
    "\n",
    "dense_3 = Dense(32,activation='selu')(bn)\n",
    "output = Dense(10,activation=\"softmax\")(dense_3)\n",
    "\n",
    "model_4 = Model(inputs=[input_layer],outputs=[output])\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:33.672380Z",
     "iopub.status.busy": "2023-01-26T10:54:33.671967Z",
     "iopub.status.idle": "2023-01-26T10:54:35.169421Z",
     "shell.execute_reply": "2023-01-26T10:54:35.167107Z",
     "shell.execute_reply.started": "2023-01-26T10:54:33.672348Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:54:34.799679: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-01-26 10:54:34.799745: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2023-01-26 10:54:35.038515: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-01-26 10:54:35.038769: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "! rm -rf ./logs/ \n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:36.783773Z",
     "iopub.status.busy": "2023-01-26T10:54:36.783365Z",
     "iopub.status.idle": "2023-01-26T10:54:36.797824Z",
     "shell.execute_reply": "2023-01-26T10:54:36.796662Z",
     "shell.execute_reply.started": "2023-01-26T10:54:36.783738Z"
    }
   },
   "outputs": [],
   "source": [
    "model_4.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:54:38.399895Z",
     "iopub.status.busy": "2023-01-26T10:54:38.399518Z",
     "iopub.status.idle": "2023-01-26T10:57:01.706627Z",
     "shell.execute_reply": "2023-01-26T10:57:01.705296Z",
     "shell.execute_reply.started": "2023-01-26T10:54:38.399860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  2/450 [..............................] - ETA: 1:35 - loss: 2.8158 - accuracy: 0.0625 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:54:39.935062: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2023-01-26 10:54:39.935110: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/450 [..............................] - ETA: 1:51 - loss: 2.6933 - accuracy: 0.1042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:54:40.194404: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-01-26 10:54:40.195361: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2023-01-26 10:54:40.327286: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 470 callback api events and 467 activity events. \n",
      "2023-01-26 10:54:40.337232: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2023-01-26 10:54:40.349601: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40\n",
      "\n",
      "2023-01-26 10:54:40.357559: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40/5dfbba354824.trace.json.gz\n",
      "2023-01-26 10:54:40.369178: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40\n",
      "\n",
      "2023-01-26 10:54:40.371135: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40/5dfbba354824.memory_profile.json.gz\n",
      "2023-01-26 10:54:40.371893: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40\n",
      "Dumped tool data for xplane.pb to logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40/5dfbba354824.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40/5dfbba354824.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40/5dfbba354824.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40/5dfbba354824.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20230126-105434/train/plugins/profile/2023_01_26_10_54_40/5dfbba354824.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 6s 9ms/step - loss: 1.0270 - accuracy: 0.6116 - val_loss: 0.6754 - val_accuracy: 0.8075\n",
      "f1_score:  0.7548611111111111  - val_f1_score:  0.8075\n",
      "Epoch 2/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.7336 - accuracy: 0.7226 - val_loss: 0.4008 - val_accuracy: 0.8725\n",
      "f1_score:  0.8128472222222223  - val_f1_score:  0.8725\n",
      "Epoch 3/25\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.7136 - accuracy: 0.7258 - val_loss: 0.3965 - val_accuracy: 0.8575\n",
      "f1_score:  0.8028472222222223  - val_f1_score:  0.8575\n",
      "Epoch 4/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6540 - accuracy: 0.7513 - val_loss: 0.4286 - val_accuracy: 0.8400\n",
      "f1_score:  0.7997222222222222  - val_f1_score:  0.8399999999999999\n",
      "Epoch 5/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6553 - accuracy: 0.7585 - val_loss: 0.6248 - val_accuracy: 0.7525\n",
      "f1_score:  0.7310416666666667  - val_f1_score:  0.7525\n",
      "Epoch 6/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6467 - accuracy: 0.7550 - val_loss: 0.4462 - val_accuracy: 0.8500\n",
      "f1_score:  0.7813888888888889  - val_f1_score:  0.85\n",
      "Epoch 7/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6687 - accuracy: 0.7458 - val_loss: 0.3433 - val_accuracy: 0.9050\n",
      "f1_score:  0.8531944444444445  - val_f1_score:  0.905\n",
      "Epoch 8/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6384 - accuracy: 0.7612 - val_loss: 0.3255 - val_accuracy: 0.8800\n",
      "f1_score:  0.8555555555555555  - val_f1_score:  0.88\n",
      "Epoch 9/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6019 - accuracy: 0.7702 - val_loss: 0.3329 - val_accuracy: 0.8700\n",
      "f1_score:  0.8447222222222223  - val_f1_score:  0.87\n",
      "Epoch 10/25\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.6272 - accuracy: 0.7660 - val_loss: 0.3774 - val_accuracy: 0.8675\n",
      "f1_score:  0.8431249999999999  - val_f1_score:  0.8675\n",
      "Epoch 11/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5980 - accuracy: 0.7744 - val_loss: 0.6634 - val_accuracy: 0.7525\n",
      "f1_score:  0.7079861111111111  - val_f1_score:  0.7525\n",
      "Epoch 12/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6013 - accuracy: 0.7737 - val_loss: 0.3397 - val_accuracy: 0.9125\n",
      "f1_score:  0.8582638888888889  - val_f1_score:  0.9125\n",
      "Epoch 13/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5940 - accuracy: 0.7753 - val_loss: 0.3562 - val_accuracy: 0.8750\n",
      "f1_score:  0.8371527777777777  - val_f1_score:  0.875\n",
      "Epoch 14/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5785 - accuracy: 0.7836 - val_loss: 0.2705 - val_accuracy: 0.9125\n",
      "f1_score:  0.8747222222222221  - val_f1_score:  0.9125\n",
      "Epoch 15/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5851 - accuracy: 0.7827 - val_loss: 0.5578 - val_accuracy: 0.7725\n",
      "f1_score:  0.7522222222222222  - val_f1_score:  0.7725000000000001\n",
      "Epoch 16/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.6033 - accuracy: 0.7742 - val_loss: 0.4160 - val_accuracy: 0.8500\n",
      "f1_score:  0.8200694444444444  - val_f1_score:  0.85\n",
      "Epoch 17/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5453 - accuracy: 0.7990 - val_loss: 0.4009 - val_accuracy: 0.8275\n",
      "f1_score:  0.8222916666666666  - val_f1_score:  0.8275\n",
      "Epoch 18/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5476 - accuracy: 0.7922 - val_loss: 0.3507 - val_accuracy: 0.8750\n",
      "f1_score:  0.8325  - val_f1_score:  0.875\n",
      "Epoch 19/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5392 - accuracy: 0.7993 - val_loss: 0.2947 - val_accuracy: 0.8875\n",
      "f1_score:  0.866875  - val_f1_score:  0.8875\n",
      "Epoch 20/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5340 - accuracy: 0.7998 - val_loss: 0.4510 - val_accuracy: 0.8500\n",
      "f1_score:  0.8176388888888889  - val_f1_score:  0.85\n",
      "Epoch 21/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5264 - accuracy: 0.8047 - val_loss: 0.3246 - val_accuracy: 0.8975\n",
      "f1_score:  0.8415277777777778  - val_f1_score:  0.8975\n",
      "Epoch 22/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5429 - accuracy: 0.7998 - val_loss: 0.2787 - val_accuracy: 0.9025\n",
      "f1_score:  0.8715972222222222  - val_f1_score:  0.9025\n",
      "Epoch 23/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5199 - accuracy: 0.8047 - val_loss: 0.2975 - val_accuracy: 0.9025\n",
      "f1_score:  0.8768055555555555  - val_f1_score:  0.9025\n",
      "Epoch 24/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5054 - accuracy: 0.8147 - val_loss: 0.3853 - val_accuracy: 0.8675\n",
      "f1_score:  0.8357638888888889  - val_f1_score:  0.8675\n",
      "Epoch 25/25\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.5180 - accuracy: 0.8082 - val_loss: 0.2708 - val_accuracy: 0.9175\n",
      "f1_score:  0.872638888888889  - val_f1_score:  0.9175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2bc97b5f50>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_lst = [f1, tensorboard_callback]\n",
    "model_4.fit(X_train_spectrogram, y_train, epochs=25, validation_data=(X_test_spectrogram, y_test), batch_size=32, callbacks=callback_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:57:08.744899Z",
     "iopub.status.busy": "2023-01-26T10:57:08.743837Z",
     "iopub.status.idle": "2023-01-26T10:57:11.974312Z",
     "shell.execute_reply": "2023-01-26T10:57:11.973054Z",
     "shell.execute_reply.started": "2023-01-26T10:57:08.744847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2a8b78356d42c9f7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2a8b78356d42c9f7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T10:57:20.320641Z",
     "iopub.status.busy": "2023-01-26T10:57:20.320240Z",
     "iopub.status.idle": "2023-01-26T10:57:20.330704Z",
     "shell.execute_reply": "2023-01-26T10:57:20.329652Z",
     "shell.execute_reply.started": "2023-01-26T10:57:20.320607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------------+----------+--------------+\n",
      "| Sr. No. |               Data               | F1 Score | Val F1 Score |\n",
      "+---------+----------------------------------+----------+--------------+\n",
      "|    1    |             Raw Data             |  0.1028  |     0.10     |\n",
      "|    2    |           Spectrogram            |  0.8592  |     0.88     |\n",
      "|    3    |  Raw Data + Data Augumentation   |   0.10   |    0.1025    |\n",
      "|    4    | Spectrogram + Data Augumentation |  0.8726  |    0.9175    |\n",
      "+---------+----------------------------------+----------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Specify the Column Names while initializing the Table\n",
    "Table = PrettyTable([\"Sr. No.\", \"Data\", \"F1 Score\", \"Val F1 Score\"])\n",
    "\n",
    "# Add rows\n",
    "Table.add_row([\"1\", \"Raw Data\", \"0.1028\", \"0.10\"])\n",
    "Table.add_row([\"2\", \"Spectrogram\", \"0.8592\", \"0.88\"])\n",
    "Table.add_row([\"3\", \"Raw Data + Data Augumentation\", \"0.10\", \"0.1025\"])\n",
    "Table.add_row([\"4\", \"Spectrogram + Data Augumentation\", \"0.8726\", \"0.9175\"])\n",
    "\n",
    "print(Table)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Speech detection Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
